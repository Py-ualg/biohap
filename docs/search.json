[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "üîó Online version of the tutorial",
    "section": "",
    "text": "üîó Online version of the tutorial\nBioHaP main deployment site",
    "crumbs": [
      "Contents",
      "üîó Online version of the tutorial"
    ]
  },
  {
    "objectID": "2025_spring/250507_taires.html",
    "href": "2025_spring/250507_taires.html",
    "title": "Microbiome Analysis of Amplicon Sequencing",
    "section": "",
    "text": "Last change\n\n\n\n\n\nJune 2, 2025\n\n\n\nThis workshop will provide an overview of microbiome data analysis from Illumina amplicon sequencing raw data to data processing, visualization and statistics. Participants will learn basic concepts and tools to preprocess (QIIME2) and analyse (MicrobiomeAnalyst) microbiome data, in particular bacteria associated with marine organisms.\nIn a coral associated microbiome dataset, where we have two different coral species (with one incipient speciation) and two different reproductive strategies, we want to address the following scientific questions:\n\nIs the microbiome of these cold-water corals species-specific?\nIs the microbiome related to the reproductive strategy?\nOr is the microbiome shaped by both factors?\n\n\n\nThis tutorial requires you to be able to run QIIME2. We provide you with access to redi server, where it is preinstalled. However if you want to set it up yourself, the full instructions areavailable at qiime2 webpage. Beware that below is UNIX specific setup. We did these parts:\n\n\n\nDownload installer from anaconda\nYour downloaded file is executable (.exe on Win, .pkg on Mac and .sh on Linux). Run the install\n\n\n\n\n# update your conda\nconda update conda\n\n# create conda environment for amplicon qiime2\nconda env create -n qiime2-amplicon-2024.10 --file https://data.qiime2.org/distro/amplicon/qiime2-amplicon-2024.10-py310-linux-conda.yml\n\n\n\n\nIn the repository, you can find almost all the necessary input files, including pdf version of Tania‚Äôs introductory presentation.\nDownload the files to your local mahcine one by one from Github. Or better, setup yourself a Gihub account and you can clone the whole biohap repository.\n\n\nTo get the data tables from the server to your PC or opposite, ssh protocol exists.\n\nLinux: should be part of the core installation\nPutty on Windows, or ssh client\nMac: part of the install\n\nOnce you have ssh setup, do ssh &lt;USERNAME&gt;@10.36.5.158, and then enter your password. You are the username connecting(@) to the server (10.36.5.158, redi).\n\n\n\n\n\n\nNote\n\n\n\n\n\nIf you are not at the University internet (eduroam or fixed), first you will need to connect to it via UAlg VPN service.\n\n\n\nIn your /home/&lt;USERNAME&gt; directory (you can see the location using pwd command), create a new folder\nmkdir workshop_qiime2\n\n# and navigate to it\ncd workshop_qiime2\nTo copy the files to the server, instead of standard cp we need to use secure scp. Note that the server address is most probbably different but the structure of the command is &lt;USERNAME&gt;@&lt;SERVER IP address&gt;:&lt;ABSOLUTE-PATH&gt;\n# scp from to, -r means with the subfolder structure (recursive)\nscp -r \"&lt;path-to-your-downloads-perhaps&gt;\\Samples\"  &lt;USERNAME&gt;@10.36.5.158:/home/&lt;USERNAME&gt;/workshop_qiime2/\n\n\n\n\n\n\nNote\n\n\n\n\n\nNote different slashes used on different operating systems. On windows, the path will be something like ‚ÄúC:‚Äù, macOS similar to ‚Äú/Users/USERNAME/Downloads/‚Äù, unix ‚Äú/home/USERNAME/Downloads‚Äù\n\n\n\nTransfer the other files in the similar manner.\n\n\n\n\n\n\nTip\n\n\n\n\n\nEvery time you are lost on the server, use pwd to print current directory you are in, ls to list contents of the directory and cd to navigate to other directories (going up the tree one level with cd ..)\n\n\n\n\n\n\nFirst look at your manifest file, which specifies sample ids, and reads filenames, in this case we use paired ends, which means two file_paths per line are present.\ncat Manifest_file_Species.txt\nThe path needs to be changed to conform with your file system location. You see weird ^M characters, let‚Äôs remove those\n\nEither use dos2unix Manifest_file_Species.txt\nOr replace them using sed\n\n# \\r/ refers to Windows line ending\nsed -i 's/\\r//g' Manifest_file_Species.txt\nRun cat command again to confirm successful substitution. Select part of the path you want to replace next.\n\nSelect with the cursor the path (this automatically enters into your clipboard), or right mouse click and select copy\nprobably something like /Users/microbiomes/Documents/Microbiomes/Coral_Microbiome_Workshop_sps_comparison/\n\nNow we substitute the string with correct path\n\n\n\n\n\n\nTip\n\n\n\n\nMiddle mouse button click pastes your mouse selection, ie clipboard on the command line\nAlternatively also right click and select paste.\nYou can get your correct path using pwd to print current folder path (assuming you are where your Samples folder is)\n\n\n\nsed -i 's|/Users/microbiomes/Documents/Microbiomes/Coral_Microbiome_Workshop_sps_comparison/|&lt;YOUR_PATH_TO_FOLDER_Samples&gt;|g' Manifest_file_Species.txt\n\n\n\n\n\n\nNote\n\n\n\n\n\nNote that since our strings contained / character we used | to separate the parts of the sed command. That was not necessary in the case above s/\\r//g where / plays a role of the separator\nsed command s: substitute our flag g means replace all occurance on the line.\ns/pattern/subtitution/flags\n\n\n\nConfirm again using cat that your manifest file is correct.\n\n\n\n\nQIIME2 is installed in a sort of container (conda environment), which allows you to work on different project which need different dependencies in parallel. First, activate the correct conda environment, which has QIIME2 installed.\nconda activate qiime2-amplicon-2024.10\nYour command line should look similar to (qiime2-amplicon-2024.10) [XXXX@redi ~]$ now. Make sure that you are in your workshop_qiime2 directory where you have also copied the files which serve as inputs for the below section (flags -i, --input-path or similar)\n\n\nqiime tools import \\\n    --type 'SampleData[PairedEndSequencesWithQuality]' \\\n    --input-path Manifest_file_Species.txt \\\n    --output-path demux.qza \\\n    --input-format PairedEndFastqManifestPhred33V2\ntype describes that we have paired ends with Q scores (fastq) inputs. input-path is our manifest file, describing where all the files are. demux.qza will be our output-path file and input-format describes your sequencing technology, PairedEndFastq means that your data was sequenced with Forward and Reverse primers and you have two fastq files per sample that should be joined. Phred33 refers to the type of Phred scores in your fastq file. This is the lastest version and used for most recent Illumina sequencers. V2 is the version of the manifest file formatting we conform to.\n\n\n\nqiime demux summarize --i-data demux.qza --o-visualization demux.qzv\n\n--i-data: input, which is output of importing data previously\n--o-visualization: output filename\n\n\n\n\nEvery time you create .qzv table, it is to be visualized at QIIME2 webpage for quality control and taking decisions for next steps. Open QIIME2 webpage and drag the qzv files in there. Use the ssh as described above to get the data to your PC.\nThis is easiest to do from your local machine side, for which you need to open additional powershell for Windows or terminal for mac users (NOT logged in to the server).\nscp &lt;USERNAME&gt;@10.36.5.158:/home/&lt;USERNAME&gt;/workshop_qiime2/demux.qzv \"absolute-path-on-your-PC-to-folder-you-want-your-file\"\nGo to https://view.qiime2.org and drag any .qzv file to visualize it.\n\n\n\ndada2 is an R package, which will be used here. This step can take substantial time and resource.\nqiime dada2 denoise-paired \\\n    --i-demultiplexed-seqs demux.qza \\\n    --p-trim-left-f x \\\n    --p-trim-left-r y \\\n    --p-trunc-len-f z \\\n    --p-trunc-len-r n \\\n    --p-n-threads 0 \\\n    --o-table table.qza \\\n    --o-representative-sequences rep-seqs.qza \\\n    --o-denoising-stats denoising-stats.qza \\\n    --verbose\n\n\n\n\n\n\nTrimming\n\n\n\nNote: When choosing where to trim the sequences, after looking at the demux file, besides taking into account that low quality nucleotides should be removed, we need to make sure that the forward (R1) and reverse (R2) sequences, after trimming, can still overlap. A good overlap may be between 20 and 100bp.\nLet‚Äôs say: - Your amplicon is 450 bp - Your reads are 250 bp each (paired-end)\nIf both reads are high-quality all the way: 250 (R1) + 250 (R2) = 500 bp, with expected overlap: ~50 bp, üçè But if you truncate reads too aggressively (e.g., with ‚Äìp-trunc-len-f 200 ‚Äìp-trunc-len-r 180), R1 becomes 200 bp, R2 becomes 180 bp. Then:\n200 + 180 = 380 &lt; 450 The sequences won‚Äôt be able to overlap,üçé\nIf, for example, all your reverse reads are very low quality (usually the quality of R2 reads are lower than R1) the analysis can be done using only R1 sequences as single-end sequences. But first, complain to your sequencing centre.\n\n\n\n--p-trim-left-f: xxx (see demux.qzv file)\n--p-trim-left-r: xxx (see demux.qzv file)\n--p-trunc-len-f: xxx (see demux.qzv file)\n--p-trunc-len-r: xxx (see demux.qzv file)\n--p-n-threads 0: xxx (the number of CPUs threads the tool should use during processing, zero means ‚Äúuse all the threads available‚Äù)\n--o-table: output table filename\n--o-representative-sequences: representative sequences file name\n--o-denoising-stats: statistics filename specification\n--verbose: write extensive progress on the screen (since this script does several things it is advisable to run it so we can follow the flow)\n\n\n\n\n\n\n\nSample output on the screen\n\n\n\n\n\nR version 4.3.3 (2024-02-29) Loading required package: Rcpp DADA2: 1.30.0 / Rcpp: 1.0.13.1 / RcppParallel: 5.1.9 2) Filtering ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶ 3) Learning Error Rates 208608800 total bases in 1043044 reads from 17 samples will be used for learning the error rates. 219039240 total bases in 1043044 reads from 17 samples will be used for learning the error rates. 3) Denoise samples ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶ ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶ 5) Remove chimeras (method = consensus) 6) Report read numbers through the pipeline 7) Write output Saved FeatureTable[Frequency] to: table.qza Saved FeatureData[Sequence] to: rep-seqs.qza Saved SampleData[DADA2Stats] to: denoising-stats.qza\n\n\n\n\n\n\nCreate .qzv files for visualizations again.\nqiime metadata tabulate \\\n    --m-input-file denoising-stats.qza \\\n    --o-visualization denoising-stats.qzv\nArguments specify input and output files.\nqiime feature-table summarize \\\n    --i-table table.qza \\\n    --o-visualization table.qzv\nAnd finally tabulate the sequences.\nqiime feature-table tabulate-seqs \\\n    --i-data rep-seqs.qza \\\n    --o-visualization rep-seqs.qzv\nUse your scp skills again to transfer denoising-stats.qzv, rep-seqs.qzv and table.qzv to your PC. Again, do it from your PC‚Äôs command line.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nscp &lt;USERNAME&gt;@10.36.5.158:/home/&lt;USERNAME&gt;/workshop_qiime2/*.qzv \"path-to-destination-folder\"\n\n\n\n\n\n\nThe database is now in the repo because of its size, download it. If you work on redi, the database is located at &lt;fill in path DP&gt;. This is also a time-consuming step\nThe classifier needs to match our scikit-learn package version used by the QIIME2 version. At redi, the version is 1.4.2, and we have already put in the shared location path /opt/shared/silva-138-99-nb-classifier.qza.\nIn other use case, download the appropriate classfier from qiime. If you use your own classifier, the below specifications of the classifier might change.\nqiime feature-classifier classify-sklearn \\\n    --i-classifier /opt/shared/silva-138-99-nb-classifier.qza \\\n    --i-reads rep-seqs.qza \\\n    --o-classification taxonomy.qza\n\n\n\nqiime metadata tabulate \\\n    --m-input-file taxonomy.qza \\\n    --o-visualization taxonomy.qzv\n\n\n\nqiime tools export \\\n    --input-path table.qza \\\n    --output-path feature-table\n\n\n\n\n\n\nNote\n\n\n\nNote: We first create a biom table from the .qza file so we can then integrate the taxonomic assignments. Biom tables can also be used in other programs for downstream analysis if you want.\n\n\n\n\n\nqiime tools export \\\n    --input-path taxonomy.qza \\\n    --output-path taxonomy\nTo move further with the analysis, open the taxonomy file and change the header. When you open it, you‚Äôll see the header looks like this:\nFeature ID Taxon   Confidence\nYou need to change it to this:\n#otu-id    taxonomy    Confidence\n\n\n\n\n\n\nImportant\n\n\n\nALL spaces are tabs\n\n\nCan you figure out the sed command do do that?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nsed -i '1s/.*/#otu-id\\ttaxonomy\\tConfidence/' ~/the_name_of_the_folder_where_you_are_working/taxonomy/taxonomy.tsv\n\n\n\nConfirm if the header has changed\nhead taxonomy/taxonomy.tsv\n\n\n\nbiom add-metadata \\\n    --input-fp feature-table/feature-table.biom \\\n    --observation-metadata-fp taxonomy/taxonomy.tsv \\\n    --output-fp biom-with-taxonomy.biom\n\n\n\nbiom convert \\\n    --input-fp biom-with-taxonomy.biom \\\n    --output-fp ASV_table.tsv \\\n    --to-tsv --header-key taxonomy\nThe output of these scripts will be two different files, a ASV_table_MA.txt file and a taxonomy_MA.txt file that are ready to upload in the MicrobiomeAnalyst program.\n\n\n\n\nUnfortunately the ASV table is not directly compatible with the MA. We need to split it into separate abundance and taxonomy tables. In the GH repo, there are two scripts to do that without going into the details. Both have hardcoded input ASV table name ASV_table.tsv which you need to conform too. Outputs will be ASV_table_MA.txt and taxonomy_MA.txt, respectively.\n\n\n\n\n\n\nPermissions\n\n\n\n\n\nRunning the shell script requires that executable (x) permissions for the file, which probably after scp is not the case. To enable execution, run:\nchmod +x convert_ASV_abundances.sh\nchmod +x convert_ASV_taxonomy.sh\nwith ls, the executable files should appear in green. The scripts accept one and one argument only which points to the ASV_table.tsv generated by QIIME2. Below it assumes your in the directory where the ASV table resides, otherwise include absolute or relative path.\n\n\n\n./convert_ASV_abundances.sh ASV_table.tsv\n./convert_ASV_taxonomy.sh  ASV_table.tsv\nTogether with the provided metadata_MA.txt, which assigns each sample to a coral species, those are the three files you need to scp to your local machine for MA web interface upload. MA can do too many things for you, the subset we will use is described in Tania‚Äôs presentation available on GH too.\n\n\n\n\n\n\nImportant\n\n\n\nIt is very important that the metadata file columns are tab separated, and the first column header is #NAME.\n\n\nThe fun starts Microbiome analyst page, Click here to start the session and select Marker data profiling.\n\n\n\nMA inputs\n\n\nYou need to select the first three input files (OTU/ASV table, Metadata file, Taxonomy table), and from the dropdown, choose Taxonomy labels to be QIIME.",
    "crumbs": [
      "Contents",
      "Microbiome Analysis of Amplicon Sequencing"
    ]
  },
  {
    "objectID": "2025_spring/250507_taires.html#setup",
    "href": "2025_spring/250507_taires.html#setup",
    "title": "Microbiome Analysis of Amplicon Sequencing",
    "section": "",
    "text": "This tutorial requires you to be able to run QIIME2. We provide you with access to redi server, where it is preinstalled. However if you want to set it up yourself, the full instructions areavailable at qiime2 webpage. Beware that below is UNIX specific setup. We did these parts:\n\n\n\nDownload installer from anaconda\nYour downloaded file is executable (.exe on Win, .pkg on Mac and .sh on Linux). Run the install\n\n\n\n\n# update your conda\nconda update conda\n\n# create conda environment for amplicon qiime2\nconda env create -n qiime2-amplicon-2024.10 --file https://data.qiime2.org/distro/amplicon/qiime2-amplicon-2024.10-py310-linux-conda.yml",
    "crumbs": [
      "Contents",
      "Microbiome Analysis of Amplicon Sequencing"
    ]
  },
  {
    "objectID": "2025_spring/250507_taires.html#input-files",
    "href": "2025_spring/250507_taires.html#input-files",
    "title": "Microbiome Analysis of Amplicon Sequencing",
    "section": "",
    "text": "In the repository, you can find almost all the necessary input files, including pdf version of Tania‚Äôs introductory presentation.\nDownload the files to your local mahcine one by one from Github. Or better, setup yourself a Gihub account and you can clone the whole biohap repository.\n\n\nTo get the data tables from the server to your PC or opposite, ssh protocol exists.\n\nLinux: should be part of the core installation\nPutty on Windows, or ssh client\nMac: part of the install\n\nOnce you have ssh setup, do ssh &lt;USERNAME&gt;@10.36.5.158, and then enter your password. You are the username connecting(@) to the server (10.36.5.158, redi).\n\n\n\n\n\n\nNote\n\n\n\n\n\nIf you are not at the University internet (eduroam or fixed), first you will need to connect to it via UAlg VPN service.\n\n\n\nIn your /home/&lt;USERNAME&gt; directory (you can see the location using pwd command), create a new folder\nmkdir workshop_qiime2\n\n# and navigate to it\ncd workshop_qiime2\nTo copy the files to the server, instead of standard cp we need to use secure scp. Note that the server address is most probbably different but the structure of the command is &lt;USERNAME&gt;@&lt;SERVER IP address&gt;:&lt;ABSOLUTE-PATH&gt;\n# scp from to, -r means with the subfolder structure (recursive)\nscp -r \"&lt;path-to-your-downloads-perhaps&gt;\\Samples\"  &lt;USERNAME&gt;@10.36.5.158:/home/&lt;USERNAME&gt;/workshop_qiime2/\n\n\n\n\n\n\nNote\n\n\n\n\n\nNote different slashes used on different operating systems. On windows, the path will be something like ‚ÄúC:‚Äù, macOS similar to ‚Äú/Users/USERNAME/Downloads/‚Äù, unix ‚Äú/home/USERNAME/Downloads‚Äù\n\n\n\nTransfer the other files in the similar manner.\n\n\n\n\n\n\nTip\n\n\n\n\n\nEvery time you are lost on the server, use pwd to print current directory you are in, ls to list contents of the directory and cd to navigate to other directories (going up the tree one level with cd ..)\n\n\n\n\n\n\nFirst look at your manifest file, which specifies sample ids, and reads filenames, in this case we use paired ends, which means two file_paths per line are present.\ncat Manifest_file_Species.txt\nThe path needs to be changed to conform with your file system location. You see weird ^M characters, let‚Äôs remove those\n\nEither use dos2unix Manifest_file_Species.txt\nOr replace them using sed\n\n# \\r/ refers to Windows line ending\nsed -i 's/\\r//g' Manifest_file_Species.txt\nRun cat command again to confirm successful substitution. Select part of the path you want to replace next.\n\nSelect with the cursor the path (this automatically enters into your clipboard), or right mouse click and select copy\nprobably something like /Users/microbiomes/Documents/Microbiomes/Coral_Microbiome_Workshop_sps_comparison/\n\nNow we substitute the string with correct path\n\n\n\n\n\n\nTip\n\n\n\n\nMiddle mouse button click pastes your mouse selection, ie clipboard on the command line\nAlternatively also right click and select paste.\nYou can get your correct path using pwd to print current folder path (assuming you are where your Samples folder is)\n\n\n\nsed -i 's|/Users/microbiomes/Documents/Microbiomes/Coral_Microbiome_Workshop_sps_comparison/|&lt;YOUR_PATH_TO_FOLDER_Samples&gt;|g' Manifest_file_Species.txt\n\n\n\n\n\n\nNote\n\n\n\n\n\nNote that since our strings contained / character we used | to separate the parts of the sed command. That was not necessary in the case above s/\\r//g where / plays a role of the separator\nsed command s: substitute our flag g means replace all occurance on the line.\ns/pattern/subtitution/flags\n\n\n\nConfirm again using cat that your manifest file is correct.",
    "crumbs": [
      "Contents",
      "Microbiome Analysis of Amplicon Sequencing"
    ]
  },
  {
    "objectID": "2025_spring/250507_taires.html#qiime2",
    "href": "2025_spring/250507_taires.html#qiime2",
    "title": "Microbiome Analysis of Amplicon Sequencing",
    "section": "",
    "text": "QIIME2 is installed in a sort of container (conda environment), which allows you to work on different project which need different dependencies in parallel. First, activate the correct conda environment, which has QIIME2 installed.\nconda activate qiime2-amplicon-2024.10\nYour command line should look similar to (qiime2-amplicon-2024.10) [XXXX@redi ~]$ now. Make sure that you are in your workshop_qiime2 directory where you have also copied the files which serve as inputs for the below section (flags -i, --input-path or similar)\n\n\nqiime tools import \\\n    --type 'SampleData[PairedEndSequencesWithQuality]' \\\n    --input-path Manifest_file_Species.txt \\\n    --output-path demux.qza \\\n    --input-format PairedEndFastqManifestPhred33V2\ntype describes that we have paired ends with Q scores (fastq) inputs. input-path is our manifest file, describing where all the files are. demux.qza will be our output-path file and input-format describes your sequencing technology, PairedEndFastq means that your data was sequenced with Forward and Reverse primers and you have two fastq files per sample that should be joined. Phred33 refers to the type of Phred scores in your fastq file. This is the lastest version and used for most recent Illumina sequencers. V2 is the version of the manifest file formatting we conform to.\n\n\n\nqiime demux summarize --i-data demux.qza --o-visualization demux.qzv\n\n--i-data: input, which is output of importing data previously\n--o-visualization: output filename\n\n\n\n\nEvery time you create .qzv table, it is to be visualized at QIIME2 webpage for quality control and taking decisions for next steps. Open QIIME2 webpage and drag the qzv files in there. Use the ssh as described above to get the data to your PC.\nThis is easiest to do from your local machine side, for which you need to open additional powershell for Windows or terminal for mac users (NOT logged in to the server).\nscp &lt;USERNAME&gt;@10.36.5.158:/home/&lt;USERNAME&gt;/workshop_qiime2/demux.qzv \"absolute-path-on-your-PC-to-folder-you-want-your-file\"\nGo to https://view.qiime2.org and drag any .qzv file to visualize it.\n\n\n\ndada2 is an R package, which will be used here. This step can take substantial time and resource.\nqiime dada2 denoise-paired \\\n    --i-demultiplexed-seqs demux.qza \\\n    --p-trim-left-f x \\\n    --p-trim-left-r y \\\n    --p-trunc-len-f z \\\n    --p-trunc-len-r n \\\n    --p-n-threads 0 \\\n    --o-table table.qza \\\n    --o-representative-sequences rep-seqs.qza \\\n    --o-denoising-stats denoising-stats.qza \\\n    --verbose\n\n\n\n\n\n\nTrimming\n\n\n\nNote: When choosing where to trim the sequences, after looking at the demux file, besides taking into account that low quality nucleotides should be removed, we need to make sure that the forward (R1) and reverse (R2) sequences, after trimming, can still overlap. A good overlap may be between 20 and 100bp.\nLet‚Äôs say: - Your amplicon is 450 bp - Your reads are 250 bp each (paired-end)\nIf both reads are high-quality all the way: 250 (R1) + 250 (R2) = 500 bp, with expected overlap: ~50 bp, üçè But if you truncate reads too aggressively (e.g., with ‚Äìp-trunc-len-f 200 ‚Äìp-trunc-len-r 180), R1 becomes 200 bp, R2 becomes 180 bp. Then:\n200 + 180 = 380 &lt; 450 The sequences won‚Äôt be able to overlap,üçé\nIf, for example, all your reverse reads are very low quality (usually the quality of R2 reads are lower than R1) the analysis can be done using only R1 sequences as single-end sequences. But first, complain to your sequencing centre.\n\n\n\n--p-trim-left-f: xxx (see demux.qzv file)\n--p-trim-left-r: xxx (see demux.qzv file)\n--p-trunc-len-f: xxx (see demux.qzv file)\n--p-trunc-len-r: xxx (see demux.qzv file)\n--p-n-threads 0: xxx (the number of CPUs threads the tool should use during processing, zero means ‚Äúuse all the threads available‚Äù)\n--o-table: output table filename\n--o-representative-sequences: representative sequences file name\n--o-denoising-stats: statistics filename specification\n--verbose: write extensive progress on the screen (since this script does several things it is advisable to run it so we can follow the flow)\n\n\n\n\n\n\n\nSample output on the screen\n\n\n\n\n\nR version 4.3.3 (2024-02-29) Loading required package: Rcpp DADA2: 1.30.0 / Rcpp: 1.0.13.1 / RcppParallel: 5.1.9 2) Filtering ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶ 3) Learning Error Rates 208608800 total bases in 1043044 reads from 17 samples will be used for learning the error rates. 219039240 total bases in 1043044 reads from 17 samples will be used for learning the error rates. 3) Denoise samples ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶ ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶ 5) Remove chimeras (method = consensus) 6) Report read numbers through the pipeline 7) Write output Saved FeatureTable[Frequency] to: table.qza Saved FeatureData[Sequence] to: rep-seqs.qza Saved SampleData[DADA2Stats] to: denoising-stats.qza\n\n\n\n\n\n\nCreate .qzv files for visualizations again.\nqiime metadata tabulate \\\n    --m-input-file denoising-stats.qza \\\n    --o-visualization denoising-stats.qzv\nArguments specify input and output files.\nqiime feature-table summarize \\\n    --i-table table.qza \\\n    --o-visualization table.qzv\nAnd finally tabulate the sequences.\nqiime feature-table tabulate-seqs \\\n    --i-data rep-seqs.qza \\\n    --o-visualization rep-seqs.qzv\nUse your scp skills again to transfer denoising-stats.qzv, rep-seqs.qzv and table.qzv to your PC. Again, do it from your PC‚Äôs command line.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nscp &lt;USERNAME&gt;@10.36.5.158:/home/&lt;USERNAME&gt;/workshop_qiime2/*.qzv \"path-to-destination-folder\"\n\n\n\n\n\n\nThe database is now in the repo because of its size, download it. If you work on redi, the database is located at &lt;fill in path DP&gt;. This is also a time-consuming step\nThe classifier needs to match our scikit-learn package version used by the QIIME2 version. At redi, the version is 1.4.2, and we have already put in the shared location path /opt/shared/silva-138-99-nb-classifier.qza.\nIn other use case, download the appropriate classfier from qiime. If you use your own classifier, the below specifications of the classifier might change.\nqiime feature-classifier classify-sklearn \\\n    --i-classifier /opt/shared/silva-138-99-nb-classifier.qza \\\n    --i-reads rep-seqs.qza \\\n    --o-classification taxonomy.qza\n\n\n\nqiime metadata tabulate \\\n    --m-input-file taxonomy.qza \\\n    --o-visualization taxonomy.qzv\n\n\n\nqiime tools export \\\n    --input-path table.qza \\\n    --output-path feature-table\n\n\n\n\n\n\nNote\n\n\n\nNote: We first create a biom table from the .qza file so we can then integrate the taxonomic assignments. Biom tables can also be used in other programs for downstream analysis if you want.\n\n\n\n\n\nqiime tools export \\\n    --input-path taxonomy.qza \\\n    --output-path taxonomy\nTo move further with the analysis, open the taxonomy file and change the header. When you open it, you‚Äôll see the header looks like this:\nFeature ID Taxon   Confidence\nYou need to change it to this:\n#otu-id    taxonomy    Confidence\n\n\n\n\n\n\nImportant\n\n\n\nALL spaces are tabs\n\n\nCan you figure out the sed command do do that?\n\n\n\n\n\n\nSolution\n\n\n\n\n\nsed -i '1s/.*/#otu-id\\ttaxonomy\\tConfidence/' ~/the_name_of_the_folder_where_you_are_working/taxonomy/taxonomy.tsv\n\n\n\nConfirm if the header has changed\nhead taxonomy/taxonomy.tsv\n\n\n\nbiom add-metadata \\\n    --input-fp feature-table/feature-table.biom \\\n    --observation-metadata-fp taxonomy/taxonomy.tsv \\\n    --output-fp biom-with-taxonomy.biom\n\n\n\nbiom convert \\\n    --input-fp biom-with-taxonomy.biom \\\n    --output-fp ASV_table.tsv \\\n    --to-tsv --header-key taxonomy\nThe output of these scripts will be two different files, a ASV_table_MA.txt file and a taxonomy_MA.txt file that are ready to upload in the MicrobiomeAnalyst program.",
    "crumbs": [
      "Contents",
      "Microbiome Analysis of Amplicon Sequencing"
    ]
  },
  {
    "objectID": "2025_spring/250507_taires.html#microbiomeanalyst-ma",
    "href": "2025_spring/250507_taires.html#microbiomeanalyst-ma",
    "title": "Microbiome Analysis of Amplicon Sequencing",
    "section": "",
    "text": "Unfortunately the ASV table is not directly compatible with the MA. We need to split it into separate abundance and taxonomy tables. In the GH repo, there are two scripts to do that without going into the details. Both have hardcoded input ASV table name ASV_table.tsv which you need to conform too. Outputs will be ASV_table_MA.txt and taxonomy_MA.txt, respectively.\n\n\n\n\n\n\nPermissions\n\n\n\n\n\nRunning the shell script requires that executable (x) permissions for the file, which probably after scp is not the case. To enable execution, run:\nchmod +x convert_ASV_abundances.sh\nchmod +x convert_ASV_taxonomy.sh\nwith ls, the executable files should appear in green. The scripts accept one and one argument only which points to the ASV_table.tsv generated by QIIME2. Below it assumes your in the directory where the ASV table resides, otherwise include absolute or relative path.\n\n\n\n./convert_ASV_abundances.sh ASV_table.tsv\n./convert_ASV_taxonomy.sh  ASV_table.tsv\nTogether with the provided metadata_MA.txt, which assigns each sample to a coral species, those are the three files you need to scp to your local machine for MA web interface upload. MA can do too many things for you, the subset we will use is described in Tania‚Äôs presentation available on GH too.\n\n\n\n\n\n\nImportant\n\n\n\nIt is very important that the metadata file columns are tab separated, and the first column header is #NAME.\n\n\nThe fun starts Microbiome analyst page, Click here to start the session and select Marker data profiling.\n\n\n\nMA inputs\n\n\nYou need to select the first three input files (OTU/ASV table, Metadata file, Taxonomy table), and from the dropdown, choose Taxonomy labels to be QIIME.",
    "crumbs": [
      "Contents",
      "Microbiome Analysis of Amplicon Sequencing"
    ]
  }
]