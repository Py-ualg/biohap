[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ðŸ”— Online version of the tutorial",
    "section": "",
    "text": "ðŸ”— Online version of the tutorial\nBioHaP main deployment site",
    "crumbs": [
      "Contents",
      "ðŸ”— Online version of the tutorial"
    ]
  },
  {
    "objectID": "biodata_pt/251117_part2.html",
    "href": "biodata_pt/251117_part2.html",
    "title": "Training on accessing, processing, and curating datasets 2025",
    "section": "",
    "text": "Because (a) public SPARQL endpoint with all the EMO-BON data, we completaly separate this second part from the first part, and data starting point will be standard .csv tables, just compressed into .parquet files. Since Blue-Cloud 2026 virtual research environment does not exist, we will run all the analysis locally.\n\nSetupBasic Panel DashboardDeeper Interactive ModeHackathon\n\n\n# create a folder\nmkdir momics-demos\ncd momics-demos\n\n# clone the repository into newly created folder\ngit clone https://github.com/emo-bon/momics-demos.git\n\n# step into the repository\ncd momics-demos\n\n# install dependencies using pip\npip install -e .\n\n# setup jupyter kernel\nipython kernel install --user --name \"emobon\"\n\n\nAll dependencies were installed in the setup. Initialize the jupyter server with\ncd momics-demos\npython -m jupyterlab\nOpen wf2_diversity/diversities_panel.ipynb. It looks and it is a native python notebook code. However clicking the panel icon  initiates the dashboard.\nAfter getting familiar with the functionality, pick your favourite combination of taxon level + categoricall variable showing certain pattern on the first two PCA components.\n\n\nEvery dashboard is also available for interactive mode ..._interactive.ipynb. After discovering one of the main drivers, we would like to see what drives this difference.\nSelect one sample from each category and try to identify the taxa responsible from the variance.\nPossible options\n\nOne approach could be the permonova test removing the taxa one by one. Permonova is implemented in marine-omics-methods (marine-omics on PyPI).\nAlternatively compute correlation of each taxon with the PC1 and PC2, rank the features\nFit features as vectors onto PCoA (envfit). This is the most widely used method, especially in ecology (vegan package in R). In Python (via scikit-bio):\n\n    from skbio.stats.ordination import cca_scores\n\n    # envfit equivalent not built-in, but you can manually regress:\n    import scipy.stats as st\n\n    results = {}\n    for feature in abund.columns:\n        slope_x, _, r_x, _, _ = st.linregress(coords[\"PC1\"], abund[feature])\n        slope_y, _, r_y, _, _ = st.linregress(coords[\"PC2\"], abund[feature])\n        results[feature] = (r_x, r_y)\n\n    vectors = pd.DataFrame(results, index=[\"r_PC1\", \"r_PC2\"]).T\n\n\nThis is a free time to try your own ideas with the data building upon the existing functionality of the momics-demos. Do not hesitate to raise issues, and reach out."
  },
  {
    "objectID": "biodata_pt/python_tools/01_fuseki_emobon.html",
    "href": "biodata_pt/python_tools/01_fuseki_emobon.html",
    "title": "Example of RO-Crates ingestion and fuseki SparQL",
    "section": "",
    "text": "set up local SparQL DB\nget several RO-Crates published\ncreate a graph and add it to the SparQL\nThis NB should mirror the tutorial working directly on fuseki\nFuseki setup\nFuseki is a java SparQL endpoint server.\nGet java\nthe server is at http://localhost:3030/#/\nPreparation of a dataset"
  },
  {
    "objectID": "biodata_pt/python_tools/01_fuseki_emobon.html#imports-and-functions-defs",
    "href": "biodata_pt/python_tools/01_fuseki_emobon.html#imports-and-functions-defs",
    "title": "Example of RO-Crates ingestion and fuseki SparQL",
    "section": "0. Imports and functions defs",
    "text": "0. Imports and functions defs\n\nimport os\nimport re\nimport json\nimport requests\n\nimport pandas as pd\n\nfrom pathlib import Path\nfrom rdflib import Graph, Namespace, URIRef, RDF\nfrom urllib.parse import urlparse\nfrom utils import sparql_json_to_df, jsonld_to_rdflib\n\npd.options.display.max_columns = None\npd.set_option(\"display.max_colwidth\", None)\n\n\nMethods\n\ndef fuseki_create_dataset(name: str) -&gt; None:\n    \"\"\"Create a new in-memory dataset in a local Apache Jena Fuseki server.\n    Args:\n        name (str): Name of the dataset to create.\n    \n    Returns:\n        None\n    \"\"\"\n    fuseki_admin_url = \"http://localhost:3030/$/datasets\"\n    # Form data\n    form_data = {\n        \"dbName\": name,   # dataset name\n        \"dbType\": \"mem\"       # in-memory\n    }\n\n    # Headers to enforce form encoding\n    headers = {\n        \"Content-Type\": \"application/x-www-form-urlencoded\"\n    }\n\n    # POST request\n    resp = requests.post(fuseki_admin_url, data=form_data, headers=headers)\n    if resp.status_code != 200:\n        print(\"Dataset creation failed for\", name, resp.status_code)\n        print(\"Server response:\", resp.text[:1000])\n    else:\n        print(\"Dataset created:\", name)\n\n\ndef create_upload_ds(name: str, contents: bytes) -&gt; None:\n    \"\"\"\n    Create a new dataset in Fuseki and upload contents to it.\n\n    Args:\n        name (str): Name of the dataset.\n        contents (bytes): RDF data in Turtle format.\n    \n    Returns:\n        None\n    \"\"\"\n    fuseki_create_dataset(name)\n\n    # Now upload the data to the named graph\n    gsp_endpoint = f\"http://localhost:3030/{name}/data\"\n    headers = {\"Content-Type\": \"text/turtle\"}     # sending Turtle\n    resp = requests.post(\n        gsp_endpoint,\n        data=contents,\n        headers=headers,\n        timeout=60,\n    )\n    if resp.status_code != 200:\n        print(\"Upload failed for dataset\", name, resp.status_code)\n        print(\"Server response:\", resp.text[:1000])\n    else:\n        print(\"Upload succeeded for dataset\", name)\n\n\n\n0.5 Get current EMO-BON RO-Crates\n\neasiest is to clone the https://github.com/emo-bon/analysis-results-cluster-01-crate repo\nsemi-hardcoded option to get data from GitHub can be found in 03_fuseki_emobon_GH.ipynb\nTODO: rewrite in existing fuseki engines such pyfuseki, https://yubincloud.github.io/pyfuseki/"
  },
  {
    "objectID": "biodata_pt/python_tools/01_fuseki_emobon.html#serialize-ro-crate-metadata.json-to-.ttl",
    "href": "biodata_pt/python_tools/01_fuseki_emobon.html#serialize-ro-crate-metadata.json-to-.ttl",
    "title": "Example of RO-Crates ingestion and fuseki SparQL",
    "section": "1. Serialize ro-crate-metadata.json to .ttl",
    "text": "1. Serialize ro-crate-metadata.json to .ttl\n\n# USER SETTINGS\nrocrate_folder = Path.home() / \"coding/ro-crates/analysis-results-cluster-01-crate/\"\nprocess_N = 10  # number of crates to process\n\n\n\n# loop over all ro-crates in the folder\ncount = 0\nfor crate_path in rocrate_folder.glob(\"*/\"):\n    if 'ro-crate-metadata.json' not in os.listdir(crate_path):\n        print(f\"Skipping {crate_path}, no ro-crate-metadata.json found.\")\n        continue\n\n    print(f\"Processing crate at {crate_path}...\")\n    with open(crate_path / \"ro-crate-metadata.json\", \"r\") as f:\n        metadata = json.load(f)\n    graph = jsonld_to_rdflib(metadata)\n\n    # Serialize to TTL format and save to file\n    ttl_content = graph.serialize(format='turtle')\n\n    # print(crate_path.parent / (crate_path.name + '.ttl'))\n    with open(crate_path.parent / (crate_path.name + '.ttl'), 'w', encoding='utf-8') as f:\n        f.write(ttl_content)\n\n    count += 1\n    if count &gt;= process_N:\n        break\n\nSkipping /home/david-palecek/coding/ro-crates/analysis-results-cluster-01-crate/.github, no ro-crate-metadata.json found.\nSkipping /home/david-palecek/coding/ro-crates/analysis-results-cluster-01-crate/.git, no ro-crate-metadata.json found.\nSkipping /home/david-palecek/coding/ro-crates/analysis-results-cluster-01-crate/.dvc, no ro-crate-metadata.json found.\nProcessing crate at /home/david-palecek/coding/ro-crates/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate..."
  },
  {
    "objectID": "biodata_pt/python_tools/01_fuseki_emobon.html#repeat-queries-but-from-python",
    "href": "biodata_pt/python_tools/01_fuseki_emobon.html#repeat-queries-but-from-python",
    "title": "Example of RO-Crates ingestion and fuseki SparQL",
    "section": "2. Repeat queries but from python",
    "text": "2. Repeat queries but from python\n\nyou should have running fuseki on the localhost:3030\nit should be manually populated with EMO-BON RO-Crates with dataset name emobon\n\n\nHow many triples do we have?\n\nq = \"\"\"\nSELECT (COUNT(*) AS ?c)\nWHERE { \n    ?s ?p ?o\n}\n\"\"\"\nr = requests.get(\"http://localhost:3030/emobon\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\nprint(r.json())\n\n{'head': {'vars': ['c']}, 'results': {'bindings': [{'c': {'type': 'literal', 'datatype': 'http://www.w3.org/2001/XMLSchema#integer', 'value': '599'}}]}}\n\n\n\ndf = sparql_json_to_df(r.json())\nprint(df)\n\n     c\n0  599\n\n\n\n\nFilter our all the text/html files\n\nq = \"\"\"\nPREFIX sdo: &lt;http://schema.org/&gt;\n\nSELECT ?x ?dtype\nWHERE {\n  ?x sdo:encodingFormat ?dtype .\n  FILTER regex(str(?dtype), \"^text/html\", \"i\")\n}\n\"\"\"\nr = requests.get(\"http://localhost:3030/emobon\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\ndf = sparql_json_to_df(r.json())\ndf\n\n\n\n\n\n\n\n\nx\ndtype\n\n\n\n\n0\nfile:///home/david-palecek/coding/biohap/biohap/biohap/biodata_pt/python_tools/taxonomy-summary/SSU/krona.html\ntext/html\n\n\n1\nfile:///home/david-palecek/coding/biohap/biohap/biohap/biodata_pt/python_tools/fastp.html\ntext/html\n\n\n2\nhttps://www.ebi.ac.uk/ena/browser/view/ERS20569012\ntext/html\n\n\n\n\n\n\n\n\n\nReturn also the sdo:downloadUrl of those files.\n\nq = \"\"\"\nPREFIX sdo: &lt;http://schema.org/&gt;\n\nSELECT ?x ?dtype ?durl\nWHERE {\n  ?x sdo:encodingFormat ?dtype ;\n     sdo:downloadUrl ?durl .\n  FILTER regex(str(?dtype), \"^text/html\", \"i\")\n}\n\"\"\"\nr = requests.get(\"http://localhost:3030/emobon\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\ndf = sparql_json_to_df(r.json())\ndf\n\n\n\n\n\n\n\n\nx\ndtype\ndurl\n\n\n\n\n0\nfile:///home/david-palecek/coding/biohap/biohap/biohap/biodata_pt/python_tools/taxonomy-summary/SSU/krona.html\ntext/html\nhttps://s3.mesocentre.uca.fr/mgf-data-products/files/md5/1f/d7f1e97dc438433527d667ad7694da\n\n\n1\nfile:///home/david-palecek/coding/biohap/biohap/biohap/biodata_pt/python_tools/fastp.html\ntext/html\nhttps://s3.mesocentre.uca.fr/mgf-data-products/files/md5/0f/28859f70d366611ab6c31110f865bb\n\n\n2\nhttps://www.ebi.ac.uk/ena/browser/view/ERS20569012\ntext/html\nhttps://www.ebi.ac.uk/ena/browser/view/ERS20569012\n\n\n\n\n\n\n\n\n\nReturn SSU taxonomy download links\n\nq = \"\"\"\nPREFIX sdo: &lt;http://schema.org/&gt;\n\nSELECT ?subject ?predicate ?object ?durl\nWHERE {\n  ?subject ?predicate ?object .\n  FILTER regex(str(?object), \"SSU-taxonomy-summary\", \"i\")\n  OPTIONAL { ?object sdo:downloadUrl ?durl }\n}\nLIMIT 50\n\"\"\"\n\nr = requests.get(\n    \"http://localhost:3030/emobon\",\n    params={\"query\": q},\n    headers={\"Accept\": \"application/sparql-results+json\"},\n)\n\ndf = sparql_json_to_df(r.json())\ndf\n\n\n\n\n\n\n\n\nsubject\npredicate\nobject\ndurl\n\n\n\n\n0\nfile:///home/david-palecek/coding/biohap/biohap/biohap/biodata_pt/python_tools/taxonomy-summary/SSU/\nhttp://schema.org/hasPart\nfile:///home/david-palecek/coding/biohap/biohap/biohap/biodata_pt/python_tools/taxonomy-summary/SSU/SSU-taxonomy-summary.ttl\nhttps://s3.mesocentre.uca.fr/mgf-data-products/files/md5/1f/2b3cb19433ecc141b977077f901f49\n\n\n\n\n\n\n\n\n\nSSU taxonomy display\n\nfrom the object values we see the taxonomy is in ttl format, which means it has been triplicated during so called semantic uplift\n\n\nurl = df[\"durl\"].dropna().unique()[0]\nr = requests.get(url)\n# save to a file\nwith open(\"ssu_example.ttl\", \"wb\") as f:\n    f.write(r.content)\n\n\nurl\n\n'https://s3.mesocentre.uca.fr/mgf-data-products/files/md5/1f/2b3cb19433ecc141b977077f901f49'\n\n\n\ng = Graph()\ng.parse(\"ssu_example.ttl\", format=\"turtle\")\n\n# Convert all triples into a list of tuples\ntriples = [(str(s), str(p), str(o)) for s, p, o in g]\n\n# Make a pandas DataFrame\ndf = pd.DataFrame(triples, columns=[\"subject\", \"predicate\", \"object\"])\ndf.head(10)\n\n\n\n\n\n\n\n\nsubject\npredicate\nobject\n\n\n\n\n0\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#875170\nhttps://data.emobon.embrc.eu/ns/product#otuID\n126289\n\n\n1\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#1185407\nhttp://www.w3.org/1999/02/22-rdf-syntax-ns#type\nhttps://data.emobon.embrc.eu/ns/product#TaxonomicAnnotation\n\n\n2\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=188972\nhttp://purl.org/dc/terms/title\nSpongomonas\n\n\n3\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=2211268\nhttp://rs.tdwg.org/dwc/terms/higherClassification\nBacteria | | Candidatus_Margulisbacteria\n\n\n4\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#444\nhttps://data.emobon.embrc.eu/ns/product#geneticMarker\nhttp://purl.obolibrary.org/obo/GO_0015935\n\n\n5\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#2024979\nhttp://www.w3.org/1999/02/22-rdf-syntax-ns#type\nhttps://data.emobon.embrc.eu/ns/product#TaxonomicAnnotation\n\n\n6\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=44746\nhttp://purl.org/dc/terms/taxonRank\nfamily\n\n\n7\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=2562242\nhttp://rs.tdwg.org/dwc/terms/higherClassification\nBacteria | | Acidobacteria | Thermoanaerobaculia | Thermoanaerobaculales\n\n\n8\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=29407\nhttp://purl.org/dc/terms/taxonRank\ngenus\n\n\n9\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=1696036\nhttp://rs.tdwg.org/dwc/terms/higherClassification\nBacteria | | Proteobacteria | Alphaproteobacteria | Holosporales | Candidatus_Paracaedibacteraceae | Candidatus_Finniella\n\n\n\n\n\n\n\n\n\nTranslate SSU triples into a taxonomy DF\n\nCOLUMNS = [\n    'ncbi_tax_id', 'abundance', 'superkingdom',\n    'kingdom', 'phylum', 'class', 'order',\n    'family', 'genus', 'species'\n]\nRANKS = ['superkingdom','kingdom','phylum','class','order','family','genus','species']\n\n# ----- helper functions -----------------------------------------------------\ndef as_str(node):\n    return None if node is None else str(node)\n\ndef extract_ncbi_id(uri_str):\n    \"\"\"Extract numeric taxid from NCBI URI or fragment like #41873.\"\"\"\n    if not uri_str:\n        return None\n    m = re.search(r'[?&]id=(\\d+)', uri_str)\n    if m:\n        return m.group(1)\n    m = re.search(r'#(\\d+)$', uri_str)\n    if m:\n        return m.group(1)\n    m = re.search(r'/(\\d+)(?:$|[/?#])', uri_str)\n    if m:\n        return m.group(1)\n    return None\n\ndef last_path_segment(uri_str):\n    if not uri_str:\n        return None\n    p = urlparse(uri_str)\n    if p.fragment:\n        return p.fragment\n    seg = p.path.rstrip('/').split('/')[-1]\n    return seg if seg != '' else None\n\n\n# ----- load graph -----------------------------------------------------------\ng = Graph()\ng.parse(\"ssu_example.ttl\", format=\"turtle\")   # &lt;-- change path if needed\n\n# ----- namespaces used in your sample --------------------------------------\nPROD = Namespace(\"https://data.emobon.embrc.eu/ns/product#\")\nDCT  = Namespace(\"http://purl.org/dc/terms/\")\nSCHEMA = Namespace(\"http://schema.org/\")  # not required here but safe\nDWC = Namespace(\"http://rs.tdwg.org/dwc/terms/\")  # not required here but safe\n\n# ----- accumulate rows keyed by (source_material_ID, ncbi_tax_id) -----------\nacc = {}  # (source_id, taxid) -&gt; dict of columns\n\ndef ensure_row(source_id, taxid):\n    key = (source_id or \"unknown_sample\", taxid or \"unknown_taxid\")\n    if key not in acc:\n        acc[key] = {col: None for col in COLUMNS}\n        acc[key]['ncbi_tax_id'] = taxid\n    return acc[key]\n\n# ----- iterate TaxonomicAnnotation nodes -----------------------------------\nfor ta_node in g.subjects(RDF.type, PROD.TaxonomicAnnotation):\n    # read annotation-level properties\n    sample_uri = g.value(ta_node, PROD.ofSample) or g.value(ta_node, DCT.ofSample)\n    source_id = last_path_segment(as_str(sample_uri))\n    identifier = g.value(ta_node, DCT.identifier)  # expected to be NCBI URI\n    identifier_s = as_str(identifier)\n    ncbi_id = extract_ncbi_id(identifier_s)\n\n    # abundance (prod:rRNA) and otuID\n    abundance_term = g.value(ta_node, PROD.rRNA)\n    # sometimes abundance literal typed - convert to int if possible\n    try:\n        abundance = int(str(abundance_term))\n    except Exception:\n        abundance = str(abundance_term)\n\n    # create/ensure row\n    row = ensure_row(source_id, ncbi_id)\n    row['abundance'] = abundance\n\n    # now look up the taxon node (identifier) and extract rank / scientificName\n    if identifier is not None:\n        tax_subject = URIRef(identifier_s)\n        sci_name_term = g.value(tax_subject, DCT.scientificName) or g.value(tax_subject, DCT.title)\n        rank_term = g.value(tax_subject, DCT.taxonRank)\n        sci_name = as_str(sci_name_term)\n        rank = as_str(rank_term).lower() if rank_term is not None else None\n\n        higher_ranks = g.value(tax_subject, DWC.higherClassification).split('| ') if g.value(tax_subject, DWC.higherClassification) else []\n        higher_ranks = [rank.strip() for rank in higher_ranks]\n        \n        if rank and sci_name:\n            # if rank is one of our expected ranks, store at that column\n            if rank in RANKS:\n                row[rank] = sci_name\n\n                # index of the rank in RANKS\n                rank_index = RANKS.index(rank)\n                # fill higher ranks if available\n                for i in range(rank_index - 1, -1, -1):\n                    if i &lt; len(higher_ranks):\n                        row[RANKS[i]] = higher_ranks[i]\n\n        else:\n            raise ValueError(f\"Missing rank or scientific name for taxon {identifier_s}\")\n\n# ----- build final DataFrame ------------------------------------------------\nout_rows = []\nfor (source_id, taxid), vals in acc.items():\n    # enforce ncbi_tax_id numeric when possible\n    try:\n        vals['ncbi_tax_id'] = int(taxid) if (taxid and taxid != \"unknown_taxid\") else None\n    except Exception:\n        vals['ncbi_tax_id'] = taxid\n    vals['source_material_ID'] = source_id\n    out_rows.append(vals)\n\ndf = pd.DataFrame(out_rows)\n\n# set index like your example and reorder columns\ndf['source_material_ID'] = df['source_material_ID'].fillna('unknown_sample')\ndf['ncbi_tax_id'] = df['ncbi_tax_id'].fillna('unknown_taxid')\n\ndf = df.set_index(['source_material_ID', 'ncbi_tax_id'])\nfinal_cols = ['abundance'] + RANKS\n# ensure columns exist in the DataFrame before slicing\nfinal_cols = [c for c in final_cols if c in df.columns]\ndf = df[final_cols].sort_index()\n\n# convert abundance to numeric (if any)\nif 'abundance' in df.columns:\n    df['abundance'] = pd.to_numeric(df['abundance'], errors='coerce')\n\nprint(df.shape)\ndf\n\n(1045, 9)\n\n\n\n\n\n\n\n\n\n\nabundance\nsuperkingdom\nkingdom\nphylum\nclass\norder\nfamily\ngenus\nspecies\n\n\nsource_material_ID\nncbi_tax_id\n\n\n\n\n\n\n\n\n\n\n\n\n\nEMOBON_OSD74_Wa_21\n2\n671.0\nNone\nNone\nNone\nNone\nNone\nNone\nNone\nNone\n\n\n10\n2.0\nBacteria\n\nProteobacteria\nGammaproteobacteria\nCellvibrionales\nCellvibrionaceae\nCellvibrio\nNone\n\n\n20\n3.0\nBacteria\n\nProteobacteria\nAlphaproteobacteria\nCaulobacterales\nCaulobacteraceae\nPhenylobacterium\nNone\n\n\n22\n4.0\nBacteria\n\nProteobacteria\nGammaproteobacteria\nAlteromonadales\nShewanellaceae\nShewanella\nNone\n\n\n29\n55.0\nBacteria\n\nProteobacteria\nDeltaproteobacteria\nMyxococcales\nNone\nNone\nNone\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2687318\n2.0\nEukaryota\n\n\nFilasterea\nNone\nNone\nNone\nNone\n\n\n2689614\n19.0\nBacteria\n\nProteobacteria\nGammaproteobacteria\nNevskiales\nSteroidobacteraceae\nNone\nNone\n\n\n2691354\n1.0\nBacteria\n\nPlanctomycetes\nPlanctomycetia\nPirellulales\nNone\nNone\nNone\n\n\n2691357\n88.0\nBacteria\n\nPlanctomycetes\nPlanctomycetia\nPirellulales\nPirellulaceae\nNone\nNone\n\n\n2699529\n2.0\nEukaryota\n\n\nBigyra\nAmphifilida\nNone\nNone\nNone\n\n\n\n\n1045 rows Ã— 9 columns"
  },
  {
    "objectID": "biodata_pt/python_tools/01_fuseki_emobon.html#create-dataset-if-not-yet-on-fuseki",
    "href": "biodata_pt/python_tools/01_fuseki_emobon.html#create-dataset-if-not-yet-on-fuseki",
    "title": "Example of RO-Crates ingestion and fuseki SparQL",
    "section": "3. Create dataset if not yet on fuseki",
    "text": "3. Create dataset if not yet on fuseki\n\n# check if dataset exists, if not create it\nfuseki_datasets_url = \"http://localhost:3030/$/datasets\"\ndataset = \"emobon_python\"   # if does not exist yet, it will be created\n\n# get existing datasets\nresp = requests.get(fuseki_datasets_url)\nresp.raise_for_status()\ndatasets_info = resp.json()\n\nexisting_datasets = [ds[\"ds.name\"] for ds in datasets_info[\"datasets\"]]\n\nprint(\"Existing datasets:\", existing_datasets)\nif dataset not in existing_datasets:\n    fuseki_create_dataset(dataset)\n\n# upload TTL content to the dataset\nfuseki_url = f\"http://localhost:3030/{dataset}/data\"\nheaders = {\"Content-Type\": \"text/turtle\"}\n\nExisting datasets: ['/emobon']\nDataset created: emobon_python\n\n\n\n# ingest one ro-crate as example\nwith open(rocrate_folder / \"EMOBON_OSD74_Wa_21-ro-crate.ttl\", \"r\") as f:\n    ttl_content = f.read()\n    \nresp = requests.put(fuseki_url, data=ttl_content.encode(\"utf-8\"), headers=headers, timeout=60)\n\n# raise for HTTP error\ntry:\n    resp.raise_for_status()\nexcept requests.HTTPError as e:\n    raise RuntimeError(f\"Upload failed: {resp.status_code} {resp.text}\") from e"
  },
  {
    "objectID": "biodata_pt/python_tools/01_fuseki_emobon.html#ingestion-to-fuseki",
    "href": "biodata_pt/python_tools/01_fuseki_emobon.html#ingestion-to-fuseki",
    "title": "Example of RO-Crates ingestion and fuseki SparQL",
    "section": "4. Ingestion to fuseki",
    "text": "4. Ingestion to fuseki\n\nLoop over ttls in a folder\n\nfor filename in os.listdir(rocrate_folder):\n    if not filename.endswith(\"-ro-crate.ttl\"):\n        continue\n\n    path = os.path.join(rocrate_folder, filename)\n    print(\"Uploading (append):\", filename)\n    with open(path, \"rb\") as f:\n        ttl_bytes = f.read()\n\n    create_upload_ds(dataset, ttl_bytes)\n\nprint(\"All files uploaded (appended).\")\n\nUploading (append): EMOBON_OSD74_Wa_21-ro-crate.ttl\nDataset creation failed for emobon_python 409\nServer response: Name already registered '/emobon_python'\n\nUpload succeeded for dataset emobon_python\nAll files uploaded (appended).\n\n\n\n\nsidetrack to DVC\n\nI want to get the ttl file from the NB, not putting the sdo:downloadUrl into the browser\n\n\nos.environ['AWS_NO_SIGN_REQUEST'] = '1'\nos.environ.pop('AWS_PROFILE', None)   # avoid using a missing profile\n\nimport dvc.api\nfrom dvc.api import DVCFileSystem\nimport boto3\nfrom botocore import UNSIGNED\nfrom botocore.client import Config\n\n\ndef get_single_file_s3(repo_folder: str, path: str) -&gt; tuple[str, bytes]:\n    \"\"\"\n    Get a single file from an S3 bucket using DVC and boto3 without credentials.\n    Args:\n        repo_folder (str): Path to the DVC repository.\n        path (str): Path to the file within the DVC repository.\n    Returns:\n        tuple[str, bytes]: Filename and file contents as bytes.\n    \"\"\"\n    url = dvc.api.get_url(\n        path=path,\n        repo=repo_folder,\n    )\n    # Custom S3 endpoint (non-AWS)\n    endpoint_url = \"https://s3.mesocentre.uca.fr\"\n    bucket = \"mgf-data-products\"\n    key = url.split(f\"{bucket}/\")[-1]  # extract key from URL\n\n    # Create S3 client that does NOT require credentials\n    s3 = boto3.client(\n        \"s3\",\n        endpoint_url=endpoint_url,\n        config=Config(signature_version=UNSIGNED),\n    )\n\n    # Fetch the object\n    obj = s3.get_object(Bucket=bucket, Key=key)\n\n    # Read contents into memory\n    data = obj[\"Body\"].read()\n\n    filename = path.split(\"/\")[1] + \"_\" + path.split(\"/\")[-1]\n    # Save to a local file if needed\n    with open(filename, \"wb\") as f:\n        f.write(data)\n\n    print(\"Downloaded\", len(data), \"bytes from\", endpoint_url)\n    return path.split(\"/\")[1], data\n\n\ndvc_fs = DVCFileSystem(rocrate_folder)\nfiles = list(dvc_fs.find(\"/\", detail=False))\nprint(files)\n\n['/.github/workflows/rocrate_to_pages.yml', '/EMOBON_OSD74_Wa_21-ro-crate.ttl', '/EMOBON_OSD74_Wa_21-ro-crate/.gitignore', '/EMOBON_OSD74_Wa_21-ro-crate/DBB.merged.cmsearch.all.tblout.deoverlapped.bz2', '/EMOBON_OSD74_Wa_21-ro-crate/DBB.merged.fasta.bz2', '/EMOBON_OSD74_Wa_21-ro-crate/DBB.merged.motus.tsv.bz2', '/EMOBON_OSD74_Wa_21-ro-crate/DBB.merged.qc_summary', '/EMOBON_OSD74_Wa_21-ro-crate/DBB.merged.unfiltered_fasta.bz2', '/EMOBON_OSD74_Wa_21-ro-crate/DBB.merged_CDS.faa.bz2', '/EMOBON_OSD74_Wa_21-ro-crate/DBB.merged_CDS.ffn.bz2', '/EMOBON_OSD74_Wa_21-ro-crate/DBB_AAHDOSDA_2_1_H5H2YDSX7.UDI239_clean.fastq.trimmed.fasta.bz2', '/EMOBON_OSD74_Wa_21-ro-crate/DBB_AAHDOSDA_2_1_H5H2YDSX7.UDI239_clean.fastq.trimmed.qc_summary', '/EMOBON_OSD74_Wa_21-ro-crate/DBB_AAHDOSDA_2_2_H5H2YDSX7.UDI239_clean.fastq.trimmed.fasta.bz2', '/EMOBON_OSD74_Wa_21-ro-crate/DBB_AAHDOSDA_2_2_H5H2YDSX7.UDI239_clean.fastq.trimmed.qc_summary', '/EMOBON_OSD74_Wa_21-ro-crate/config.yml', '/EMOBON_OSD74_Wa_21-ro-crate/fastp.html', '/EMOBON_OSD74_Wa_21-ro-crate/final.contigs.fa.bz2', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/.gitignore', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/DBB.merged.emapper.summary.eggnog', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/DBB.merged.hmm.tsv.gz', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/DBB.merged.summary.go', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/DBB.merged.summary.go_slim', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/DBB.merged.summary.ips', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/DBB.merged.summary.ko', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/DBB.merged.summary.pfam', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/DBB.merged_CDS.I5.tsv.gz', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/functional-annotation.ttl', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/stats/.gitignore', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/stats/go.stats', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/stats/interproscan.stats', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/stats/ko.stats', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/stats/orf.stats', '/EMOBON_OSD74_Wa_21-ro-crate/functional-annotation/stats/pfam.stats', '/EMOBON_OSD74_Wa_21-ro-crate/ro-crate-metadata.json', '/EMOBON_OSD74_Wa_21-ro-crate/run.yml', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/.gitignore', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/5S.fa.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/5_8S.fa.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/Bacteria_large_SRP.RF01854.fasta.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/Bacteria_small_SRP.RF00169.fasta.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/LSU_rRNA_archaea.RF02540.fa.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/LSU_rRNA_bacteria.RF02541.fa.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/LSU_rRNA_eukarya.RF02543.fa.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/RNaseP_arch.RF00373.fasta.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/RNaseP_bact_a.RF00010.fasta.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/RNaseP_bact_b.RF00011.fasta.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/RNase_MRP.RF00030.fasta.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/SSU_rRNA_archaea.RF01959.fa.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/SSU_rRNA_bacteria.RF00177.fa.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/SSU_rRNA_eukarya.RF01960.fa.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/alpha_tmRNA.RF01849.fasta.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/cyano_tmRNA.RF01851.fasta.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/tRNA-Sec.RF01852.fasta.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/tRNA.RF00005.fasta.gz', '/EMOBON_OSD74_Wa_21-ro-crate/sequence-categorisation/tmRNA.RF00023.fasta.gz', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/.gitignore', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/LSU/.gitignore', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/LSU/DBB.merged_LSU.fasta.mseq.gz', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/LSU/DBB.merged_LSU.fasta.mseq.tsv', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/LSU/DBB.merged_LSU.fasta.mseq.txt', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/LSU/DBB.merged_LSU.fasta.mseq_hdf5.biom', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/LSU/DBB.merged_LSU.fasta.mseq_json.biom', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/LSU/LSU-taxonomy-summary.ttl', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/LSU/krona.html', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/RNA-counts', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/SSU/.gitignore', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/SSU/DBB.merged_SSU.fasta.mseq.gz', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/SSU/DBB.merged_SSU.fasta.mseq.tsv', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/SSU/DBB.merged_SSU.fasta.mseq.txt', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/SSU/DBB.merged_SSU.fasta.mseq_hdf5.biom', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/SSU/DBB.merged_SSU.fasta.mseq_json.biom', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/SSU/SSU-taxonomy-summary.ttl', '/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/SSU/krona.html', '/README.md']\n\n\n\nFilter SSU taxonomy tables\n\nfilt_files = [f for f in files if f.endswith(\"SSU-taxonomy-summary.ttl\")]\n[k for k in filt_files]\n\n['/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/SSU/SSU-taxonomy-summary.ttl']\n\n\n\n\nGet SSU tables and upload them to a single graph\n\ndataset = \"ssu\"\nfor file in filt_files:\n    _, contents = get_single_file_s3(rocrate_folder, file)\n    print(\"Uploading (append):\", file)\n\n    create_upload_ds(dataset, contents)\n\nDownloaded 814680 bytes from https://s3.mesocentre.uca.fr\nUploading (append): /EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/SSU/SSU-taxonomy-summary.ttl\n 814680 bytes from https://s3.mesocentre.uca.fr\nUploading (append): /EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary/SSU/SSU-taxonomy-summary.ttl\nDataset created: ssu\nUpload succeeded for dataset ssu"
  },
  {
    "objectID": "biodata_pt/python_tools/01_fuseki_emobon.html#sparql-filtering",
    "href": "biodata_pt/python_tools/01_fuseki_emobon.html#sparql-filtering",
    "title": "Example of RO-Crates ingestion and fuseki SparQL",
    "section": "5. SPARQL filtering",
    "text": "5. SPARQL filtering\n\nNow we can demonstrate queries across several graphs\nThis is the future added value to organize data in graphs\nOnce somebody hosts MGnify data in SPARQL endpoint, you can query all MGnify/metaGOflow data at once\n\n\nq = \"\"\"\nPREFIX prod:  &lt;https://data.emobon.embrc.eu/ns/product#&gt;\nPREFIX dct:   &lt;http://purl.org/dc/terms/&gt;\nPREFIX schema:&lt;https://schema.org/&gt;\nPREFIX xsd:   &lt;http://www.w3.org/2001/XMLSchema#&gt;\n\nSELECT ?annotation ?otuID ?abundance ?sample ?taxonIRI ?taxonName ?taxonRank\nWHERE {\n  # annotation node carrying the abundance\n  ?annotation a prod:TaxonomicAnnotation ;\n              prod:rRNA ?abundance ;\n              prod:otuID ?otuID ;\n              prod:ofSample ?sample ;\n              dct:identifier ?taxonIRI .\n\n  # optional taxon metadata reachable from the taxon IRI\n  OPTIONAL { ?taxonIRI dct:scientificName ?taxonName }\n  OPTIONAL { ?taxonIRI dct:taxonRank ?taxonRank }\n\n  FILTER ( xsd:double(?abundance) &gt; 20 )    # numeric filter\n  FILTER ( regex(str(?taxonRank), \"^family\", \"i\"))\n}\nORDER BY DESC(xsd:double(?abundance))\n\"\"\"\n\n\nr = requests.get(\"http://localhost:3030/ssu\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\ndf = sparql_json_to_df(r.json())\ndf\n\n\n\n\n\n\n\n\nannotation\notuID\nabundance\nsample\ntaxonIRI\ntaxonName\ntaxonRank\n\n\n\n\n0\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nfamily\n\n\n1\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#31989\n223669\n372.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=31989\nRhodobacteraceae\nfamily\n\n\n2\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#49546\n23045\n371.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=49546\nFlavobacteriaceae\nfamily\n\n\n3\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#2448023\n161694\n313.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=2448023\nIlumatobacteraceae\nfamily\n\n\n4\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#666507\n167366\n209.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=666507\nPhycisphaeraceae\nfamily\n\n\n5\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#89374\n152476\n194.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=89374\nSaprospiraceae\nfamily\n\n\n6\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#338190\n104349\n150.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=338190\nNitrosopumilaceae\nfamily\n\n\n7\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#246874\n46651\n139.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=246874\nCryomorphaceae\nfamily\n\n\n8\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#3010\n93830\n129.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=3010\nFucaceae\nfamily\n\n\n9\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#1914233\n28264\n118.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=1914233\nGemmataceae\nfamily\n\n\n10\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#1706372\n64056\n111.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=1706372\nHalieaceae\nfamily\n\n\n11\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#80864\n225602\n99.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=80864\nComamonadaceae\nfamily\n\n\n12\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#2691357\n69752\n88.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=2691357\nPirellulaceae\nfamily\n\n\n13\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#574976\n9807\n63.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=574976\nHolophagaceae\nfamily\n\n\n14\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#213119\n14312\n60.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=213119\nDesulfobacteraceae\nfamily\n\n\n15\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#213121\n23209\n60.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=213121\nDesulfobulbaceae\nfamily\n\n\n16\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#119060\n97987\n55.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=119060\nBurkholderiaceae\nfamily\n\n\n17\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#481\n166796\n54.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=481\nNeisseriaceae\nfamily\n\n\n18\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#27999\n177263\n49.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=27999\nPerkinsidae\nfamily\n\n\n19\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#1706374\n133665\n44.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=1706374\nPorticoccaceae\nfamily\n\n\n20\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#563835\n133613\n37.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=563835\nChitinophagaceae\nfamily\n\n\n21\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#206379\n94120\n34.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=206379\nNitrosomonadaceae\nfamily\n\n\n22\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#45404\n2660\n33.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=45404\nBeijerinckiaceae\nfamily\n\n\n23\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#72294\n5608\n30.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=72294\nCampylobacteraceae\nfamily\n\n\n24\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#1706375\n70441\n28.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=1706375\nSpongiibacteraceae\nfamily\n\n\n25\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#1055686\n102262\n27.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=1055686\nSandaracinaceae\nfamily\n\n\n26\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#403\n38824\n25.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=403\nMethylococcaceae\nfamily\n\n\n27\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#135617\n227844\n23.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=135617\nThiotrichaceae\nfamily\n\n\n28\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#292628\n202222\n23.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=292628\nAnaerolineaceae\nfamily\n\n\n29\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#41297\n147727\n22.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=41297\nSphingomonadaceae\nfamily\n\n\n30\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#468\n186210\n21.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=468\nMoraxellaceae\nfamily\n\n\n\n\n\n\n\n\nWikipedia query\n\nq = \"\"\"\nPREFIX wdt:  &lt;http://www.wikidata.org/prop/direct/&gt;\nPREFIX rdfs:  &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\nPREFIX schema: &lt;https://schema.org/&gt;\n\nSELECT ?item ?label ?wikipediaPage ?ncbi ?mesh \nWHERE {\n  SERVICE &lt;https://query.wikidata.org/sparql&gt; {\n    ?item wdt:P225 \"Flavobacteriaceae\" .\n    ?item rdfs:label ?label .\n    FILTER(LANG(?label) = \"en\")\n    OPTIONAL { ?item wdt:P685 ?ncbi }   # NCBI Taxon ID\n    # Find the Wikidata item whose MeSH descriptor ID is the same string\n    OPTIONAL { ?item wdt:P672 ?mesh }\n  }\n}\nLIMIT 10\n\"\"\"\n\nr = requests.get(\"http://localhost:3030/ssu\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\ndf = sparql_json_to_df(r.json())\ndf\n\n\n\n\n\n\n\n\nitem\nlabel\nwikipediaPage\nncbi\nmesh\n\n\n\n\n0\nhttp://www.wikidata.org/entity/Q5458145\nFlavobacteriaceae\nNone\n49546\nB03.440.080.190\n\n\n1\nhttp://www.wikidata.org/entity/Q5458145\nFlavobacteriaceae\nNone\n49546\nB03.440.400.425.310\n\n\n\n\n\n\n\n\n\nUniProt\n\nexample queries, https://sparql.uniprot.org/.well-known/sparql-examples/\n\n\nq = \"\"\"\nPREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\nPREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\nPREFIX taxon: &lt;http://purl.uniprot.org/taxonomy/&gt;\nPREFIX up: &lt;http://purl.uniprot.org/core/&gt;\n\nSELECT ?protein ?organism ?sequence\nWHERE {\n    ?protein a up:Protein ;\n             up:organism ?organism ;\n             up:sequence ?seqNode .\n    ?seqNode rdf:value ?sequence .\n    \n    # Only proteins under taxon 49546\n    ?organism rdfs:subClassOf taxon:49546 .\n}\nLIMIT 100\n\"\"\" \n\nr = requests.get(\"https://sparql.uniprot.org/sparql\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\ndf = sparql_json_to_df(r.json())\ndf\n\n\n\n\n\n\n\n\nprotein\norganism\nsequence\n\n\n\n\n0\nhttp://purl.uniprot.org/uniprot/A0A023BMI4\nhttp://purl.uniprot.org/taxonomy/1317122\nMYSRTHFSELLSLIPRYKFNQFVLKYSADKHNKGFNSWTHLVTMVFSQLSKANSLREIETSFNSVVNAHFHMGARSIKRSTLSEANQKRDFRVFADLANELMKNFRPSKQKELKEFLFLLDSSPIILQGRHFDWTNKTRNYNNGLKLHMLYDTHTTTPTYIDITASNINDINIGRELPIQPNATYVFDKGYTDYNWWFSIHKKQSFFVTRFKKNAATHIIEELPINKSDTQLVLADQKVIFKNKTPRGGKINQYTVPLRKITIRRDNKNTPLVIATNDFNKSAGEIASLYKKRWDIELFFKWIKQNLKIKRFIGTSLNAVKTQIYTAIITYLLSLKLQKLKENTLPFYLFLEKLSALLFVPVTLIKNDGHSQKKKDQLLIKQQLNFSW\n\n\n1\nhttp://purl.uniprot.org/uniprot/A0A023BMI7\nhttp://purl.uniprot.org/taxonomy/1317122\nMDFTIRKGSHTVSRLTCHIVWSTKYRYKVLRGDIQIRCRELLIQICDAEGIEILKGVVSADHVHMHIEYAPKLSVSYVVKQLKGRTSRKLQQEFHSLQDRYWGKHFWANGYGVWSTGNITDKMVNEYLEHHRRDNNDNSNFILE\n\n\n2\nhttp://purl.uniprot.org/uniprot/A0A023BMJ1\nhttp://purl.uniprot.org/taxonomy/1317122\nMKLPKTYIKIPITELGELRFMQDTLLDNLSLLSQTEDNFSTNRSIKDNMYWISKILVAIAEIDQRREFDDLELEKK\n\n\n3\nhttp://purl.uniprot.org/uniprot/A0A023BMJ3\nhttp://purl.uniprot.org/taxonomy/1317122\nMKKIIFVVFFLMTYIGFSQDYGFLFKTEVQATAHANLFNASVVTDSPEVYPGIGYNSTPQNVGSIYYDFIELNNNFNTATVNLYSHWISLSDPVSCNSDDTYTYTRNEFINNLVGYNTKDCNFFTIVYPIHIIEPSANEFCPDQEIVLKYGYHWQFSFDGINWNSFPTSLNTKRVTSFTLKELFSLSGIPDSQWQSESNIKFQTGYRTEFTNIRNITIINCSPKLDGPIIDIQPLCSNSINHNDNDNGSFTVTFDRELDDTKQEKMNLQVYRQVGSSFDGYASKVVTKSDFTGTSYTWEPKNLPGGVYKLFWQTKSNNEGFDDINTVPDAYDESNPFTLTTPPALSVSGAPSPVQCFGGNDGSITVTPNGGTPGTPPTSPRYQYSIDNGTTWQQETLFDSLTKGDYTILIKDNNGCEATSAPITVNERFLTIPDVVGLSALITSPTLINGNNGRIAISVSSGSGNYTNYAWTKDGNPFTPPSGSTNTNIINLYEGVYTIVVTDSNGCSSNLETFTLTDPEPIDISINMTPNTVNCSDTKVNLIASATGGFLNSGGDYTYLWDDGTTEASLTNVGIGNYQVTVSDQGGNSQSKSFQVQGPEPITAIPTVSNVGCKNGSDGTIQLTINGGTGQYTVNWTKLFDNT\n\n\n4\nhttp://purl.uniprot.org/uniprot/A0A023BMJ6\nhttp://purl.uniprot.org/taxonomy/1317122\nMIDQGLNFNIFNIIILIGIFQGPIFALIVFFNKNYRFLANYFLVSTALALSFNNFQYWLLDTGMVNELYFQIPFEFLIMSMFYPFVDEYLQIKSPKKIILAIIVPFFTSFIFRLIMKFGLITLSNDLIHILLTLEEYLSLVFSVSMITIILIKIHKYEKAKTDFNLSEIKAKTKWLKQALVFGIIICVFWVFVIQDNIARFEDDLSKYYPLWIIISILVYWIVYKGIIETQIFNQRIEIRNDTIEFTYNGQKTAYINDDFFLEIKSFIINEKLYLNPNLNLDLVAEKFNVSIGHLSKTVNKNANQSFTDFVNQLRVNESKKMLLNPNYKNYTIEAIGYESGFYSKSNFYAAFKKETNQTPSAFRLRK\n\n\n...\n...\n...\n...\n\n\n95\nhttp://purl.uniprot.org/uniprot/A0A023BMZ8\nhttp://purl.uniprot.org/taxonomy/1317122\nMKFENLIICVLTGFVVVSGYTQEKTIDTTLVNELQEVVLTATRTERQLSSLPLPVTIVSQETIKQSGTIRLNEILNEQTGIITVADESGFEGVQIQGIASDYILILIDGVPLVGRKAGNFDVNRLTVGNIKQVEVVKGPSSSLYGSEALGGVINIITEKPKSDVLSGNASYRIGSYTQQDINVDIKQRIKKLGYGVFANRFSSEGYDLTPDTAGQTVNPFENYTFNGRLYYDFSDQFSLFLSGRLYTQYQDAGFTTNTTSFEGDSEEKEWNSHLRLDHKWSDHLTTQYEFYYTNYNAKEQLADSSSGDIVSDSDFDQRLLRPEIRTTYAFKDSSKLTFGVGFQYDELDRTFFDKQVDFNSQYVYAQYDTHLIERLNVITGARFDNHSEYSNQFSPKLALRYKITEALAAKASVGYGFKAPDFRQLYFDFTNSTVGYTVLGYNVALEKLNELQAQGQILDVVVPESSLQDPLEAENSIGYNAGLTYKENRWNAELNFFRNDFKNLIDTRVIARKTNGQNVFSYFNFDKIYTTGLEFNTNYRITDNVRLSAGYQLLYAFDKEKERLVKNGEVFARDPETNQTVAVSRSEYFGLVNRSRHNANFKVFYDIVSAKANINLRLLYRSKYALFDTNGNDLIDDYDTSFVDGFAIANIAASKTFYENFTLQIGANNLFDYTKDNIPTLPGIQLYAKLNYQF\n\n\n96\nhttp://purl.uniprot.org/uniprot/A0A023BMZ9\nhttp://purl.uniprot.org/taxonomy/1317122\nMKKKHFLLISVSLLMSQGLLAQDHSTHSSPGSLGAEQIFGLLEMPFLAIALIFSFLTATKLKGGKFGSGMTLLAWGFVVMALGHLHMQIAHIFDYNIFKNIFGDTFGNYIWFIALILTWGLSALGFYKIYKASKI\n\n\n97\nhttp://purl.uniprot.org/uniprot/A0A023BN00\nhttp://purl.uniprot.org/taxonomy/1317122\nMKVNVHQNIKILVLVLSILFSLQKSYSQNDNFWSNVSFGGNLGIGFGNDTFSGVIEPSALYNFNEQFAAGMGVSFGYIESNNFTATNYGGSLLAFYSPIREIRLSLEFQEMGVSRTLEIENAQDLKENYWYPSLFVGGGYRMGNVSVGIRYDLLYDSDKSIYGSAYTPFVSVFF\n\n\n98\nhttp://purl.uniprot.org/uniprot/A0A023BN01\nhttp://purl.uniprot.org/taxonomy/1317122\nMTPVVSGFSKLSKADKIKWLAKHHFNDDQNAVDTLVTYWNSDDGLQQLHDEFTENTISNYYLPFSVAPNFLINNKRYTLPMAIEESSVVAAASKAAKFWQTRGGFKAEVLSTIKVGQVHFTYNGKPEKLQQFFSIIKPKLLASVSHMTKNMEKRGGGVIDIELRDKTSEIDDYYQLHCTFETVDAMGANFINSCLEQFAKTMTTEAKEHHDFSATEKDIEIVMSILSNYVPQCLVKASVSCNIKDLPSSPSLSPLQYANKFVRAVRIAEVEPYRAVTHNKGIMNGIDAVVLATGNDFRAIEAGAHAYASRDGKYTSLTHAEIQNEMLTFSIKLPLALGTVGGLTSLHPLVKFALQLLEKPNAKKLMEITAVAGLAQNFAAINSLITTGIQQGHMKMHLMNILNQFKATENEKKQLIKYFETNAVTHSEVVTQIEKLRA\n\n\n99\nhttp://purl.uniprot.org/uniprot/A0A023BN02\nhttp://purl.uniprot.org/taxonomy/1317122\nMKNVKKWNYILIIFLSIATISIQSCSKDDDAAGPQPNPNTDTPGTTGGDTGTDSGTNGDGGSITLYKVDGDKIIKEKDYNVTGKLLEFQKDTKKHEEIWDLVKKIVPPDYRSKMSEFVIFAGENDGTAGYVVERTPDLSKWQMGIAIDFAYQGGFNARGELAYTIVHEFGHIITLDKVQVDSSVSQENCKNFFTGEGCSRDNSNINKLYQNHWADIWEEFRKVNNQSDAQKFYDKYKERYVTQYASTNPGEDIAEIFATFVTRAGGVNGSSRAEKKIQMMYDNAEMIKLRNYIRGNIAKSSRSFLPLPGSWKNANTFGNKNKTHCSIHKH\n\n\n\n\n100 rows Ã— 3 columns\n\n\n\n\nq = \"\"\"\nPREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\nPREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\nPREFIX taxon: &lt;http://purl.uniprot.org/taxonomy/&gt;\nPREFIX up: &lt;http://purl.uniprot.org/core/&gt;\n\nSELECT (COUNT(?protein) AS ?proteinCount)\nWHERE {\n    ?protein a up:Protein ;\n             up:organism ?organism ;\n             up:sequence ?seqNode .\n    ?seqNode rdf:value ?sequence .\n\n    ?organism rdfs:subClassOf taxon:49546 .\n}\n\n\"\"\"\nr = requests.get(\"https://sparql.uniprot.org/sparql\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\ndf = sparql_json_to_df(r.json())\ndf\n\n\n\n\n\n\n\n\nproteinCount\n\n\n\n\n0\n2829119"
  },
  {
    "objectID": "biodata_pt/python_tools/01_fuseki_emobon.html#total-query",
    "href": "biodata_pt/python_tools/01_fuseki_emobon.html#total-query",
    "title": "Example of RO-Crates ingestion and fuseki SparQL",
    "section": "Total query",
    "text": "Total query\n\nq = \"\"\"\nPREFIX prod:  &lt;https://data.emobon.embrc.eu/ns/product#&gt;\nPREFIX dct:   &lt;http://purl.org/dc/terms/&gt;\nPREFIX schema:&lt;https://schema.org/&gt;\nPREFIX xsd:   &lt;http://www.w3.org/2001/XMLSchema#&gt;\nPREFIX wdt:  &lt;http://www.wikidata.org/prop/direct/&gt;\nPREFIX rdfs:  &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\nPREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\nPREFIX taxon: &lt;http://purl.uniprot.org/taxonomy/&gt;\nPREFIX up: &lt;http://purl.uniprot.org/core/&gt;\n\nSELECT ?annotation ?otuID ?abundance ?sample ?taxonIRI ?taxonTitle ?taxonName ?taxonRank ?item ?label ?wikipediaPage ?ncbi ?mesh\nWHERE {\n  {\n    SELECT ?annotation ?otuID ?abundance ?sample ?taxonIRI ?taxonTitle ?taxonName ?taxonRank\n    WHERE {\n      ?annotation a prod:TaxonomicAnnotation ;\n                  prod:rRNA ?abundance ;\n                  prod:otuID ?otuID ;\n                  prod:ofSample ?sample ;\n                  dct:identifier ?taxonIRI .\n      OPTIONAL { ?taxonIRI dct:title ?taxonTitle }\n      OPTIONAL { ?taxonIRI dct:scientificName ?taxonName }\n      OPTIONAL { ?taxonIRI dct:taxonRank ?taxonRank }\n\n      FILTER(xsd:double(?abundance) &gt; 20)\n      FILTER(regex(str(?taxonRank), \"^family\", \"i\"))\n    }\n    ORDER BY DESC(xsd:double(?abundance))\n    LIMIT 1\n  }\n\n  SERVICE &lt;https://query.wikidata.org/sparql&gt; {\n    ?item wdt:P225 ?taxonName .\n    ?item rdfs:label ?label .\n    FILTER(LANG(?label) = \"en\")\n    OPTIONAL { ?item wdt:P685 ?ncbi }   # NCBI Taxon ID\n    # Find the Wikidata item whose MeSH descriptor ID is the same string\n    OPTIONAL { ?item wdt:P672 ?mesh }\n  }\n}\n\"\"\"\n\n\nr = requests.get(\"http://localhost:3030/ssu\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\ndf = sparql_json_to_df(r.json())\ndf\n\n\n\n\n\n\n\n\nannotation\notuID\nabundance\nsample\ntaxonIRI\ntaxonTitle\ntaxonName\ntaxonRank\nitem\nlabel\nwikipediaPage\nncbi\nmesh\n\n\n\n\n0\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nSporichthyaceae\nfamily\nhttp://www.wikidata.org/entity/Q20739360\nSporichthyaceae\nNone\n85033\nNone\n\n\n\n\n\n\n\n\ntax_id = df.loc[0, \"ncbi\"]\nq = f\"\"\"\nPREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\nPREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\nPREFIX taxon: &lt;http://purl.uniprot.org/taxonomy/&gt;\nPREFIX up: &lt;http://purl.uniprot.org/core/&gt;\n\nSELECT ?taxon ?protein ?organism ?sequence\nWHERE {{\n    ?protein a up:Protein ;\n             up:organism ?organism ;\n             up:sequence ?seqNode .\n    ?seqNode rdf:value ?sequence .\n    \n    # Only proteins under taxon\n    ?organism rdfs:subClassOf taxon:{tax_id} .\n    BIND({tax_id} AS ?taxon)\n}}\nLIMIT 100\n\"\"\" \n\nr = requests.get(\"https://sparql.uniprot.org/sparql\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\ndf_prot = sparql_json_to_df(r.json())\ndf_prot\n\n\n\n\n\n\n\n\ntaxon\nprotein\norganism\nsequence\n\n\n\n\n0\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YGZ8\nhttp://purl.uniprot.org/taxonomy/1891644\nMSVEIIAIALLVGMFVLATLKPINIGLLGLVGTLVVGNLLLGMSDEELLENFPVKIVLTIIGVTYFFGMAGANGTIDLLVSWAIRLAGRRTSAVPWMIFAFASILTLLGTFSPAAVALFAPAAMGYARRVGYSPVAMCAIVICGAHAGAFSPISVSGVLVHSIAADNGITIDKWSLFGANYLLNLAFAIGTVAVCAALRRRGRGDAPVEPRGADLGSPDVSGRGTPAGGTGGTGGASGTGGATAVATRPTTQAAVTVEQRVTLGLIVVLLLSVLVLEVPISLASITVGVLLSFWRLPHQKEAIAAISWPTVLLVGGMVTYMGVLQEIGAVDQLSSAAIAVGSPILVALLLSFAMGITSAFASSTALLAALIPLALPVIDSGISATGIAIALAFSATAVDVSPFSTNGALMLASAAESERARLFRSLIIYTAVIVVLAPVVAWLAFVVLG\n\n\n1\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YH14\nhttp://purl.uniprot.org/taxonomy/1891644\nMSTPPPDPSVNPADPSVNPADPSVNPADPSVNSVDPRETIDDERAETVEIDPQDVAPAIEAVLLVVDTPTATVDIARAVGVPQDVASEVLQQLQSEYDEQGRGFQLREAAGGWRLYTREQYAGPVERFVLDGQKTRLTQAALETLAVIAYRQPVTRARVSAIRGVNVDGVVRTLLLRELIEESGHEEGSGGGLLSTTALFLEKIGLPSLQDLPPIAPLLPDVDPQMDERLETGLAELTEMTEMD\n\n\n2\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YH32\nhttp://purl.uniprot.org/taxonomy/1891644\nMANSARTTKHLFVTGGVASSLGKGLTASSLGTLLKARGLRVTMQKLDPYLNVDPGTMNPFQHGEVFVTEDGAETDLDIGHYERFLDVNLHGSANVTTGQVYSNVIAKERRGEYLGDTVQVIPHITNEIKDRVLAMADSDPNGEFIDVVITEVGGTVGDIESLPFLEAARQVRHEVGRDNCFFLHVSLVPYLAPSGELKTKPTQHSVAALRNIGIQPDAIVCRADREIPDSLKAKIALMCDVDQEAVVAAVDAPSIYDIPKVVHTEGLDAYVVRRLGLPFRDVDWSVWGDLLERVHEPTDEVTIALVGKYVDLPDAYLSVSEALRAGGFAHRAKVNLTWVPSDDCETEAGAARVLAKADGILIPGGFGIRGIEGKVGAIRFARTNGIPLLGLCLGLQCMVIEAARNLAGLEGANSAEFDPEADYPVIATMADQTDVVAGQRDMGGTMRLGSYEARLEPGSVAASAYGATTVHERHRHRYEVNNEYREKIEAAGLVFSGTSPDGRLVEFCELPAEQHPFFVGTQAHPELKSRPTNPHPLFAAFIKAALEYADGTKLPVAVDE\n\n\n3\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YH33\nhttp://purl.uniprot.org/taxonomy/1891644\nMRVGVPRERKNHEYRVAITPAGVRELHLHGHEVLIERNAGRGSQISDDEYADAGARLVASAEEVWGEGELVLKVKEPIAAEYGLMREGQVLFTYLHLAASRSCTEAIIDAKTTAVAYEMVQSADGSLPLLAPMSEVAGCLAPQVAAHYLMKPSGGKGVLLGGVAGVHSGRVVVIGAGVSGVHAARIAVGLAADVRLLDINVDALRAADRYFRGDVQTIVSSTHAVEEEVLAADVVIGAVLVPGAKAPVVVSNDLVARMRPGSVLVDIAVDQGGCFEDTRPTTHDDPTYQVHDCTFYAVSNMPGAVPNTSTYALTNVTLPYAVALADKGFERAVHDNAALAAGVNAVDGQLTAPAVAAAHDLPSVALGDVL\n\n\n4\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YH42\nhttp://purl.uniprot.org/taxonomy/1891644\nMNADAIAELMVDLFSRLADDNSSSHPTQTGLDPDTQDLLAMHYLKEAKLAIARLEREMLATTTLDYTTLGSALGISKQAARQKVRVAKEAQEQIEQQTQAGTPRFAPITLEWAARNLPPARTRSGQALNRSLAGAADPHEDLPERPLTRDFTIETVARGAKRIRTTDEPAGRAS\n\n\n...\n...\n...\n...\n...\n\n\n95\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YI80\nhttp://purl.uniprot.org/taxonomy/1891644\nMSTPPAPPPPDVDLTAVRARIDQTVEDMVDECGARLDELSDELAPVTDAMRQYSRGGKRIRALFGYAAWRATATAASQPSEEQVLAAVSAFELVQAAALAHDDIIDASDSRRGKPSMHVGFAAIHEQAGWRGNGAEFGTHAAILAGDQLLIWADAALQRANLPLEIFAAVRTEYDAMRLEVISGQYLDVLEEVRPAEASRAEERALRVAELKAASYTIARPMRIGATLAGAPATTISTFATFGHHLGIAFQLRDDLLGVFGDPAVTGKPAGDDLREGKRTVLLARTHARTDSPPVLERVGASDLSAVEIDQLRTLMRESGAVGDVEELIEQHTALATEALARVELDPAGAAALAALTDAAVRRAA\n\n\n96\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YI81\nhttp://purl.uniprot.org/taxonomy/1891644\nMPEAIEVRKVPLHNVSDASELAKLIDEGVMDADRVIAVIGKTEGNGGVNDYTRIIADRAFREVIVAKGTRTPDEVAEIPIVWSGGTDGVISPHATIFATVAPEQAVQTDEPRLTVGFAMSEQLLPEDIGYVSMVKKVADGVKVAMERAGITDPKDVHYVQTKTPLLTIHTIRDAKSRGKKVWTENTHESMDLSNGCTALGIAVALGEIEMPTDEDVMHNRDLYSSVASCSSGVELDQAQIVVVGNAPGVGGRYRIGHSVMNDALDQDGIWGAIKDAGLELPERPHTSDIGGRLVNVFLKCEASQDGEVHGRRNAMLDDSDVHWHRQIKSCVGGVTAAVTGDPAVFVSVSAAHQGPEGGGPVAAIVDLGDDPTGYQAP\n\n\n97\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YI82\nhttp://purl.uniprot.org/taxonomy/1891644\nMGHWTYLAILVGTLLAAAWLQLLPGVNVFGQPRRWLLSLLPGTAFLVWDVVVAERGWWAFAEQYTLGPRILGLPLEEIAFFLVVPTCAILGYEAVRTVLAARR\n\n\n98\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YI83\nhttp://purl.uniprot.org/taxonomy/1891644\nMKMLELENVVVNYGAIEALHGIDLQVNEGEVVSMIGANGAGKSTTMRAISGIRPLTTGRIVFEGKDITKLAPHKRVTMGICQAPEGRGIFPGMTVLENLDMGTFARKVGSKKEYDDLVEHIFELFPRLGERKEQRGGLMSGGEQQMLAIGRALMSRPKLLMLDEPSLGLAPKIIQQIFKIISEINAEGTTILLVEQNAQGALSRSNRAYILETGTVTKTGSGKDLLNDPAVMEAYLGVA\n\n\n99\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YI85\nhttp://purl.uniprot.org/taxonomy/1891644\nMPRRQRAVILVTHAGRPDVVELARQVVAQLQDADTRVYAPAEEIAPLGCTDVVPLPEPDESGQVLIDELEPEFVVVLGGDGTFLRAAEYAHPSGAAMLGVNLGHVGFLAETEPEMVTEAIDHLLGGTYRIEERLALQAAVFDPKRSREVRRTWALNEVSLEKTRRERILEIAIGVDGHPLTSFGCDGILCATPTGSTAYAFSAGGPVVWPQVEAMLVVPNAAHALFARPLVVAPTSVITLDVAPHDHDAILAADGRRLITVPAGHRVVIQRDPRPIRVARFHTEDFADRLVAKFRLPTSGFRGL\n\n\n\n\n100 rows Ã— 4 columns"
  },
  {
    "objectID": "biodata_pt/python_tools/01_fuseki_emobon.html#final-df-merge-data-from-local-emo-bon-wikipedia-uniprot",
    "href": "biodata_pt/python_tools/01_fuseki_emobon.html#final-df-merge-data-from-local-emo-bon-wikipedia-uniprot",
    "title": "Example of RO-Crates ingestion and fuseki SparQL",
    "section": "Final DF merge, data from local EMO-BON + wikipedia + UniProt!!!",
    "text": "Final DF merge, data from local EMO-BON + wikipedia + UniProt!!!\n\n# merge dataframes\ndf_merged = df.merge(df_prot, how=\"left\", left_on=\"ncbi\", right_on=\"taxon\")\ndf_merged\n\n\n\n\n\n\n\n\nannotation\notuID\nabundance\nsample\ntaxonIRI\ntaxonTitle\ntaxonName\ntaxonRank\nitem\nlabel\nwikipediaPage\nncbi\nmesh\ntaxon\nprotein\norganism\nsequence\n\n\n\n\n0\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nSporichthyaceae\nfamily\nhttp://www.wikidata.org/entity/Q20739360\nSporichthyaceae\nNone\n85033\nNone\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YGZ8\nhttp://purl.uniprot.org/taxonomy/1891644\nMSVEIIAIALLVGMFVLATLKPINIGLLGLVGTLVVGNLLLGMSDEELLENFPVKIVLTIIGVTYFFGMAGANGTIDLLVSWAIRLAGRRTSAVPWMIFAFASILTLLGTFSPAAVALFAPAAMGYARRVGYSPVAMCAIVICGAHAGAFSPISVSGVLVHSIAADNGITIDKWSLFGANYLLNLAFAIGTVAVCAALRRRGRGDAPVEPRGADLGSPDVSGRGTPAGGTGGTGGASGTGGATAVATRPTTQAAVTVEQRVTLGLIVVLLLSVLVLEVPISLASITVGVLLSFWRLPHQKEAIAAISWPTVLLVGGMVTYMGVLQEIGAVDQLSSAAIAVGSPILVALLLSFAMGITSAFASSTALLAALIPLALPVIDSGISATGIAIALAFSATAVDVSPFSTNGALMLASAAESERARLFRSLIIYTAVIVVLAPVVAWLAFVVLG\n\n\n1\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nSporichthyaceae\nfamily\nhttp://www.wikidata.org/entity/Q20739360\nSporichthyaceae\nNone\n85033\nNone\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YH14\nhttp://purl.uniprot.org/taxonomy/1891644\nMSTPPPDPSVNPADPSVNPADPSVNPADPSVNSVDPRETIDDERAETVEIDPQDVAPAIEAVLLVVDTPTATVDIARAVGVPQDVASEVLQQLQSEYDEQGRGFQLREAAGGWRLYTREQYAGPVERFVLDGQKTRLTQAALETLAVIAYRQPVTRARVSAIRGVNVDGVVRTLLLRELIEESGHEEGSGGGLLSTTALFLEKIGLPSLQDLPPIAPLLPDVDPQMDERLETGLAELTEMTEMD\n\n\n2\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nSporichthyaceae\nfamily\nhttp://www.wikidata.org/entity/Q20739360\nSporichthyaceae\nNone\n85033\nNone\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YH32\nhttp://purl.uniprot.org/taxonomy/1891644\nMANSARTTKHLFVTGGVASSLGKGLTASSLGTLLKARGLRVTMQKLDPYLNVDPGTMNPFQHGEVFVTEDGAETDLDIGHYERFLDVNLHGSANVTTGQVYSNVIAKERRGEYLGDTVQVIPHITNEIKDRVLAMADSDPNGEFIDVVITEVGGTVGDIESLPFLEAARQVRHEVGRDNCFFLHVSLVPYLAPSGELKTKPTQHSVAALRNIGIQPDAIVCRADREIPDSLKAKIALMCDVDQEAVVAAVDAPSIYDIPKVVHTEGLDAYVVRRLGLPFRDVDWSVWGDLLERVHEPTDEVTIALVGKYVDLPDAYLSVSEALRAGGFAHRAKVNLTWVPSDDCETEAGAARVLAKADGILIPGGFGIRGIEGKVGAIRFARTNGIPLLGLCLGLQCMVIEAARNLAGLEGANSAEFDPEADYPVIATMADQTDVVAGQRDMGGTMRLGSYEARLEPGSVAASAYGATTVHERHRHRYEVNNEYREKIEAAGLVFSGTSPDGRLVEFCELPAEQHPFFVGTQAHPELKSRPTNPHPLFAAFIKAALEYADGTKLPVAVDE\n\n\n3\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nSporichthyaceae\nfamily\nhttp://www.wikidata.org/entity/Q20739360\nSporichthyaceae\nNone\n85033\nNone\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YH33\nhttp://purl.uniprot.org/taxonomy/1891644\nMRVGVPRERKNHEYRVAITPAGVRELHLHGHEVLIERNAGRGSQISDDEYADAGARLVASAEEVWGEGELVLKVKEPIAAEYGLMREGQVLFTYLHLAASRSCTEAIIDAKTTAVAYEMVQSADGSLPLLAPMSEVAGCLAPQVAAHYLMKPSGGKGVLLGGVAGVHSGRVVVIGAGVSGVHAARIAVGLAADVRLLDINVDALRAADRYFRGDVQTIVSSTHAVEEEVLAADVVIGAVLVPGAKAPVVVSNDLVARMRPGSVLVDIAVDQGGCFEDTRPTTHDDPTYQVHDCTFYAVSNMPGAVPNTSTYALTNVTLPYAVALADKGFERAVHDNAALAAGVNAVDGQLTAPAVAAAHDLPSVALGDVL\n\n\n4\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nSporichthyaceae\nfamily\nhttp://www.wikidata.org/entity/Q20739360\nSporichthyaceae\nNone\n85033\nNone\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YH42\nhttp://purl.uniprot.org/taxonomy/1891644\nMNADAIAELMVDLFSRLADDNSSSHPTQTGLDPDTQDLLAMHYLKEAKLAIARLEREMLATTTLDYTTLGSALGISKQAARQKVRVAKEAQEQIEQQTQAGTPRFAPITLEWAARNLPPARTRSGQALNRSLAGAADPHEDLPERPLTRDFTIETVARGAKRIRTTDEPAGRAS\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n95\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nSporichthyaceae\nfamily\nhttp://www.wikidata.org/entity/Q20739360\nSporichthyaceae\nNone\n85033\nNone\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YI80\nhttp://purl.uniprot.org/taxonomy/1891644\nMSTPPAPPPPDVDLTAVRARIDQTVEDMVDECGARLDELSDELAPVTDAMRQYSRGGKRIRALFGYAAWRATATAASQPSEEQVLAAVSAFELVQAAALAHDDIIDASDSRRGKPSMHVGFAAIHEQAGWRGNGAEFGTHAAILAGDQLLIWADAALQRANLPLEIFAAVRTEYDAMRLEVISGQYLDVLEEVRPAEASRAEERALRVAELKAASYTIARPMRIGATLAGAPATTISTFATFGHHLGIAFQLRDDLLGVFGDPAVTGKPAGDDLREGKRTVLLARTHARTDSPPVLERVGASDLSAVEIDQLRTLMRESGAVGDVEELIEQHTALATEALARVELDPAGAAALAALTDAAVRRAA\n\n\n96\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nSporichthyaceae\nfamily\nhttp://www.wikidata.org/entity/Q20739360\nSporichthyaceae\nNone\n85033\nNone\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YI81\nhttp://purl.uniprot.org/taxonomy/1891644\nMPEAIEVRKVPLHNVSDASELAKLIDEGVMDADRVIAVIGKTEGNGGVNDYTRIIADRAFREVIVAKGTRTPDEVAEIPIVWSGGTDGVISPHATIFATVAPEQAVQTDEPRLTVGFAMSEQLLPEDIGYVSMVKKVADGVKVAMERAGITDPKDVHYVQTKTPLLTIHTIRDAKSRGKKVWTENTHESMDLSNGCTALGIAVALGEIEMPTDEDVMHNRDLYSSVASCSSGVELDQAQIVVVGNAPGVGGRYRIGHSVMNDALDQDGIWGAIKDAGLELPERPHTSDIGGRLVNVFLKCEASQDGEVHGRRNAMLDDSDVHWHRQIKSCVGGVTAAVTGDPAVFVSVSAAHQGPEGGGPVAAIVDLGDDPTGYQAP\n\n\n97\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nSporichthyaceae\nfamily\nhttp://www.wikidata.org/entity/Q20739360\nSporichthyaceae\nNone\n85033\nNone\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YI82\nhttp://purl.uniprot.org/taxonomy/1891644\nMGHWTYLAILVGTLLAAAWLQLLPGVNVFGQPRRWLLSLLPGTAFLVWDVVVAERGWWAFAEQYTLGPRILGLPLEEIAFFLVVPTCAILGYEAVRTVLAARR\n\n\n98\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nSporichthyaceae\nfamily\nhttp://www.wikidata.org/entity/Q20739360\nSporichthyaceae\nNone\n85033\nNone\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YI83\nhttp://purl.uniprot.org/taxonomy/1891644\nMKMLELENVVVNYGAIEALHGIDLQVNEGEVVSMIGANGAGKSTTMRAISGIRPLTTGRIVFEGKDITKLAPHKRVTMGICQAPEGRGIFPGMTVLENLDMGTFARKVGSKKEYDDLVEHIFELFPRLGERKEQRGGLMSGGEQQMLAIGRALMSRPKLLMLDEPSLGLAPKIIQQIFKIISEINAEGTTILLVEQNAQGALSRSNRAYILETGTVTKTGSGKDLLNDPAVMEAYLGVA\n\n\n99\nhttps://data.emobon.embrc.eu/analysis-results-cluster-01-crate/EMOBON_OSD74_Wa_21-ro-crate/taxonomy-summary-SSU/SSU-taxonomy-summary#85033\n125520\n602.0\nhttp://data.emobon.embrc.eu/observatory-osd74-crate/water/sample/EMOBON_OSD74_Wa_21\nhttps://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=85033\nSporichthyaceae\nSporichthyaceae\nfamily\nhttp://www.wikidata.org/entity/Q20739360\nSporichthyaceae\nNone\n85033\nNone\n85033\nhttp://purl.uniprot.org/uniprot/A0A7L4YI85\nhttp://purl.uniprot.org/taxonomy/1891644\nMPRRQRAVILVTHAGRPDVVELARQVVAQLQDADTRVYAPAEEIAPLGCTDVVPLPEPDESGQVLIDELEPEFVVVLGGDGTFLRAAEYAHPSGAAMLGVNLGHVGFLAETEPEMVTEAIDHLLGGTYRIEERLALQAAVFDPKRSREVRRTWALNEVSLEKTRRERILEIAIGVDGHPLTSFGCDGILCATPTGSTAYAFSAGGPVVWPQVEAMLVVPNAAHALFARPLVVAPTSVITLDVAPHDHDAILAADGRRLITVPAGHRVVIQRDPRPIRVARFHTEDFADRLVAKFRLPTSGFRGL\n\n\n\n\n100 rows Ã— 17 columns"
  },
  {
    "objectID": "biodata_pt/251117_part1.html",
    "href": "biodata_pt/251117_part1.html",
    "title": "Training on accessing, processing, and curating datasets 2025",
    "section": "",
    "text": "There are many parallel technologies to employ in each step. The pipeline here relies on fuseki for exposing the SPARQL endpoint and uses python to query the graph.\n\nRO-CratesFuseki ServerSPARQLPython SPARQLLocal + Public Endpoints\n\n\nA RO-Crate is an integrated view through which you can see an entire Research Object; the methods, the data, the output and the outcomes of a project or a piece of work. Linking all this together enables the sharing of research outputs with their context, as a coherent whole. https://www.researchobject.org\n\n\n\nImage credit: Goble, C. (2024, February 16). FAIR Digital Research Objects: Metadata Journeys. University of Auckland Seminar, Auckland. Zenodo. https://doi.org/10.5281/zenodo.10710142\n\n\nNote that we already have some of the EMO-BON RO-Crates locall in /emobon_demo/ro-crates/analysis-results-cluster-01-crate/.\nDescription of all the contents of a RO-Crate is contained in its root directory in the ro-crate-metadata.json, strictly with this name. We cannot upload directly the ro-crate-metadata.json files to the SPARQL endpoint, first they need to be serialized. We do that in the jupyter notebook.\nInitialize the jupyterlab server\n# ideally in the biohap folder\npython -m jupyterlab\nOpen biohap/biodata_pt/python_tools/01_fuseki_emobon.ipynb. Run Section 0, imports and function definitions. Section 1 serializes ro-crate0metadata.json files to turtle (.ttl) compatible with graph ingestion. Do note forget to change the relative path from your home to the analysis-results-cluster-01-crate folder.\n\n\nExpose your triples as a SPARQL end-point accessible over HTTP. Fuseki provides REST-style interaction with your RDF data, here running locally on localhost. Navigate to your downloaded fuseki files, open the archive if you have not done it yet and start the server\ncd apache-jena-fuseki-5.6.0/\n\n# start the server\n./fuseki-server\nThis should show you similar to\n15:46:47 INFO  Config          :: Fuseki Base = /home/david-palecek/coding/apache-jena-fuseki-5.6.0/run\n15:46:47 INFO  Config          :: No databases: dir=/home/david-palecek/coding/apache-jena-fuseki-5.6.0/run/configuration\n15:46:48 INFO  Config          :: UI Base = fuseki-server.jar\n15:46:48 INFO  Shiro           :: Shiro configuration: file:/home/david-palecek/coding/apache-jena-fuseki-5.6.0/run/shiro.ini\nNow opening a default fuseki port 3030 at http://localhost:3030/, you should see something like\n\n\n\nfuseki server\n\n\n\nUpload Dataset / Graph\nIn fuseki, go new dataset -&gt; give it a name emobon -&gt; add data -&gt; select the .ttl files we serialized in section RO-Crates and upload all or one by one.\nHow to create new dataset and upload data to it from python is shown in Section 3 and 4. of the biohap/biodata_pt/python_tools/01_fuseki_emobon.ipynb notebook.\nPseudo code for serialization of ro-crate-metadata.json and data upload (no new dataset creation) would look like\n# read the json file and convert it to a graph\nwith open(\".../ro-crate-metadata.json\", \"r\", encoding=\"utf-8\") as f:\n    jsonld_text = f.read()\n\ng = Graph()\n# rdflib accepts a JSON-LD string as input; base is optional\ng.parse(data=jsonld_text, format=\"json-ld\", publicID=base)\n\n# upload data to the endpoint\nresp = requests.put(\n    FUSEKI_URL,\n    data=g.serialize(format=\"turtle\").encode(\"utf-8\"),\n    headers={\"Content-Type\": \"text/turtle\"},\n    timeout=60,\n)\nThe example which integrates getting rocrates from GH directly is in biohap/biodata_pt/python_tools/02_fuseki_emobon_GH.ipynb or online.\n\n\n\nThe direct way from fuseki is to edit the query in actions. See more detailed but accesible introduction with examples. When you click query, the default query is shown\nPREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\nPREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\nSELECT * WHERE {\n  ?sub ?pred ?obj .\n} LIMIT 10\n, which queries all the triples in the graph.\n\n\n\n\n\n\nHow many triples do we have?\n\n\n\n\n\nSELECT (COUNT(*) as ?c)\nWHERE {\n  ?subject ?predicate ?object .\n}\nLIMIT 10\n\n\n\n\n\n\n\n\n\nFilter out all the text/html files.\n\n\n\n\n\nPREFIX sdo: &lt;http://schema.org/&gt;\n\nSELECT ?x ?dtype\nWHERE {\n  ?x sdo:encodingFormat ?dtype .\n  FILTER regex(str(?dtype), \"^text/html\", \"i\")\n}\n\n\n\n\n\n\n\n\n\nReturn also the sdo:downloadUrl of those files.\n\n\n\n\n\nPREFIX sdo: &lt;http://schema.org/&gt;\n\nSELECT ?x ?dtype ?durl\nWHERE {\n  ?x sdo:encodingFormat ?dtype ;\n    sdo:downloadUrl ?durl .\n  FILTER regex(str(?dtype), \"^text/html\", \"i\")\n}\n\n\n\nNow you can click the link of one of the Krona files, open them in the browser and with no surprise, it is a Krona plot.\nNow letâ€™s get the real metaGOflow outputs, specifically SSU taxonomy tables. There are several ways how to do it.\n1. RO-Crate browser EMBRC hosts the RO-Crate viewer for the EMO-BON data\n2. Local SPARQL Write a query to get the sdo:downloadUrl links, put them into your browser, which automatically triggers the download. Hint for the exercise below, match regex of the object on â€œSSU-taxonomy-summaryâ€.\n\n\n\n\n\n\nReturn SSU taxonomy download links.\n\n\n\n\n\nPREFIX sdo: &lt;http://schema.org/&gt;\n\nSELECT ?subject ?predicate ?object ?durl\nWHERE {\n  ?subject ?predicate ?object .\n  FILTER regex(str(?object), \"SSU-taxonomy-summary\", \"i\")\n  OPTIONAL { ?object sdo:downloadUrl ?durl }\n}\nLIMIT 50\n\n\n\n3. Use data version control (DVC) tool Shown in the python implementation of the above, which follows in the next section. For more on dvc, check its documentation.\n\n\nIt is possible to export the tables form the fuseki for subsequent work, but letâ€™s do everything seamlessly from the jupyter notebook.\nFirst we reproduce the queries in Section 2 of biohap/biodata_pt/python_tools/01_fuseki_emobon.ipynb notebook (or online)\nThe jupyterlab server should be still running, if not start it again in the .../biohap folder.\npython -m jupyterlab\nSince we have already ingested the triples from the RO-Crates, we just need to query the existing endpoint\nq = \"\"\"\nSELECT (COUNT(*) AS ?c) \nWHERE { \n  ?s ?p ?o\n}\n\"\"\"\n\nr = requests.get(\"http://localhost:3030/emobon/query\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\nprint(r.json())\nIn the requests target, you see we query emobon dataset, which we created earlier. The returned json is relatively easy to convert to a dataframe (sparql_json_to_df function)\ndef sparql_json_to_df(sparql_json):\n    \"\"\"\n    Convert a SPARQL SELECT query JSON result to a pandas DataFrame.\n    \n    Parameters\n    ----------\n    sparql_json : dict\n        JSON returned by Fuseki / SPARQL endpoint with Accept: application/sparql-results+json\n    \n    Returns\n    -------\n    pd.DataFrame\n    \"\"\"\n    vars_ = sparql_json.get(\"head\", {}).get(\"vars\", [])\n    rows = []\n\n    for binding in sparql_json.get(\"results\", {}).get(\"bindings\", []):\n        row = {}\n        for var in vars_:\n            # Some results might not bind all variables\n            if var in binding:\n                row[var] = binding[var][\"value\"]\n            else:\n                row[var] = None\n        rows.append(row)\n\n    df = pd.DataFrame(rows, columns=vars_)\n    return df\n\n\nThe point behind setting up SPARQL graph database comes together when combining local EMO-BON queries with public SPARQL endpoints from wikidata and UniProt. Demonstration is performed in Section 5 of the biohap/biodata_pt/python_tools/01_fuseki_emobon.ipynb.\n\n\n\n\n\n\nTip\n\n\n\nThere is a python wrapper for SPARQL SPARQLWrapper, which is pip installable and can be used as a standard python module but also as a command line script.\n\n\nBeyond only getting the data, Graph based deep learning is a fast-growing field."
  },
  {
    "objectID": "biodata_pt/python_tools/02_fuseki_emobon_GH.html",
    "href": "biodata_pt/python_tools/02_fuseki_emobon_GH.html",
    "title": "RO-Crates and SparQL",
    "section": "",
    "text": "set up local SparQL DB\nbased on few RO-Crates so far published\ntest methods to query the SparQL\n\ndirectly\nor using UDAL :TODO\n\n\nFuseki setup\nFuseki is a java SparQL endpoint server.\nGet java\nsudo apt update\nsudo apt install -y openjdk-17-jre-headless\njava -version\n\ndownload the zip file from https://jena.apache.org/download/index.cgi\nrun the fuseki server script\n\ncd apache-jena-fuseki-5.6.0/\n./fuseki-server\nthe server is at http://localhost:3030/#/\nPreparation of a dataset\n\nI want to keep this in pure python\nuse rdflib rdflib-jsonld requests\n\n\nimport pandas as pd\nimport requests\nimport json\nimport re\nfrom rdflib import Graph\nfrom urllib.parse import quote_plus, urljoin\n\nfrom utils import sparql_json_to_df, jsonld_to_rdflib\n\n\nMethods to get RO-Crates from GH\n\ndef fetch_rocrate_json_from_github(url):\n    \"\"\"\n    Try to obtain the ro-crate-metadata.json (or .jsonld) from a GitHub repo URL\n    or a raw.githubusercontent.com URL.\n    Returns text of JSON-LD.\n    \"\"\"\n    # quick case: raw URL or direct file link\n    if \"raw.githubusercontent.com\" in url or url.endswith(\".json\") or url.endswith(\".jsonld\"):\n        r = requests.get(url, timeout=20)\n        r.raise_for_status()\n        return r.text\n\n    # try to parse owner/repo from a normal GitHub URL\n    m = re.search(r\"github.com/([^/]+)/([^/]+)\", url)\n    if not m:\n        raise ValueError(\"Provide a GitHub repo url or direct raw URL to ro-crate-metadata.json\")\n\n    owner, repo = m.group(1), m.group(2).replace(\".git\", \"\")\n    # try main and master branches, common filenames\n    branches = [\"main\", \"master\"]\n    filenames = [\"ro-crate-metadata.json\", \"ro-crate-metadata.jsonld\", \"ro-crate-metadata.jsonld.json\"]\n    for br in branches:\n        for fn in filenames:\n            raw = f\"https://raw.githubusercontent.com/{owner}/{repo}/{br}/{fn}\"\n            r = requests.get(raw, timeout=15)\n            if r.status_code == 200:\n                return r.text\n    raise FileNotFoundError(f\"Could not find ro-crate-metadata.json in {owner}/{repo} (tried main/master). \"\n                            \"If your file is elsewhere, pass its raw URL directly.\")\n\n\ndef upload_graph_to_fuseki(graph, fuseki_dataset_base, graph_uri=None, method=\"POST\", fmt=\"turtle\"):\n    \"\"\"\n    Upload an rdflib.Graph to Fuseki using the Graph Store HTTP endpoint.\n    - fuseki_dataset_base: e.g. \"http://localhost:3030/rocrate\" (no trailing slash)\n    - graph_uri: if provided, data will be loaded into that named graph (as a graph IRI)\n    - method: \"POST\" (append) or \"PUT\" (replace)\n    - fmt: serialization format for upload ('turtle' recommended)\n    Returns requests.Response\n    \"\"\"\n    if not fuseki_dataset_base.endswith(\"/\"):\n        fuseki_dataset_base = fuseki_dataset_base\n    gsp_url = fuseki_dataset_base.rstrip(\"/\") + \"/data\"\n    params = {}\n    headers = {}\n\n    # serialize\n    payload = graph.serialize(format=fmt)\n    # content type mapping\n    ct = {\n        \"turtle\": \"text/turtle\",\n        \"nt\": \"application/n-triples\",\n        \"json-ld\": \"application/ld+json\",\n        \"trig\": \"application/trig\",\n        \"nquads\": \"application/n-quads\"\n    }.get(fmt, \"text/turtle\")\n\n    headers[\"Content-Type\"] = ct\n\n    # add graph query parameter if named graph\n    if graph_uri:\n        gsp_url = gsp_url + \"?graph=\" + quote_plus(graph_uri)\n\n    # choose requests method\n    if method.upper() == \"POST\":\n        resp = requests.post(gsp_url, data=payload.encode(\"utf-8\"), headers=headers, timeout=60)\n    elif method.upper() == \"PUT\":\n        resp = requests.put(gsp_url, data=payload.encode(\"utf-8\"), headers=headers, timeout=60)\n    else:\n        raise ValueError(\"method must be 'POST' or 'PUT'\")\n\n    # raise for HTTP error\n    try:\n        resp.raise_for_status()\n    except requests.HTTPError as e:\n        raise RuntimeError(f\"Upload failed: {resp.status_code} {resp.text}\") from e\n\n    return resp\n\n\ndef process_github_rocrate(repo_url, fuseki_dataset_base, graph_uri=None, branch=None, fmt=\"turtle\"):\n    \"\"\"\n    High level: fetch ro-crate metadata from GitHub, parse, upload.\n    - repo_url: github repo url or raw file url\n    - fuseki_dataset_base: e.g. 'http://localhost:3030/rocrate'\n    - graph_uri: optional named graph IRI; if None uses default graph\n    - fmt: how to serialize before upload (turtle is robust)\n    \"\"\"\n    jsonld_text = fetch_rocrate_json_from_github(repo_url)\n    g = jsonld_to_rdflib(jsonld_text)\n    # optional: add provenance triple identifying source\n    if graph_uri:\n        # keep graph_uri separate (we upload into that graph)\n        pass\n    resp = upload_graph_to_fuseki(g, fuseki_dataset_base, graph_uri=graph_uri, method=\"POST\", fmt=fmt)\n    return resp\n\n\n\n\nSerialization to .ttl\n\ndef serialize_rocrate_to_ttl(repo_url, output_file_path):\n    \"\"\"\n    Fetch RO-Crate metadata from GitHub, parse it, and serialize to a TTL file.\n    \n    Parameters\n    ----------\n    repo_url : str\n        GitHub repo URL or raw file URL to ro-crate-metadata.json\n    output_file_path : str\n        Path where the TTL file should be saved\n    \n    Returns\n    -------\n    str\n        Path to the created TTL file\n    \"\"\"\n    # Fetch and parse the RO-Crate metadata\n    jsonld_text = fetch_rocrate_json_from_github(repo_url)\n    g = jsonld_to_rdflib(jsonld_text)\n    \n    # Serialize to TTL format and save to file\n    ttl_content = g.serialize(format='turtle')\n    \n    with open(output_file_path, 'w', encoding='utf-8') as f:\n        f.write(ttl_content)\n    \n    print(f\"RO-Crate serialized to TTL file: {output_file_path}\")\n    print(f\"Graph contains {len(g)} triples\")\n    \n    return output_file_path\n\n\ndef serialize_multiple_rocrates_to_ttl(repo_urls, output_file_path):\n    \"\"\"\n    Fetch multiple RO-Crate metadata files from GitHub, parse them, \n    and serialize all to a single TTL file.\n    \n    Parameters\n    ----------\n    repo_urls : list\n        List of GitHub repo URLs or raw file URLs to ro-crate-metadata.json\n    output_file_path : str\n        Path where the combined TTL file should be saved\n    \n    Returns\n    -------\n    str\n        Path to the created TTL file\n    \"\"\"\n    # Create a combined graph\n    combined_graph = Graph()\n    \n    for i, repo_url in enumerate(repo_urls):\n        try:\n            print(f\"Processing {i+1}/{len(repo_urls)}: {repo_url}\")\n            jsonld_text = fetch_rocrate_json_from_github(repo_url)\n            g = jsonld_to_rdflib(jsonld_text)\n            \n            # Add all triples from this graph to the combined graph\n            for triple in g:\n                combined_graph.add(triple)\n                \n            print(f\"  Added {len(g)} triples\")\n            \n        except Exception as e:\n            print(f\"  FAILED to process {repo_url}: {e}\")\n    \n    # Serialize combined graph to TTL format and save to file\n    ttl_content = combined_graph.serialize(format='turtle')\n    \n    with open(output_file_path, 'w', encoding='utf-8') as f:\n        f.write(ttl_content)\n    \n    print(f\"\\nCombined RO-Crates serialized to TTL file: {output_file_path}\")\n    print(f\"Combined graph contains {len(combined_graph)} triples\")\n    \n    return output_file_path\n\n\n# Example usage of TTL serialization functions\n\n# Serialize a single RO-Crate to TTL\nsingle_repo = 'https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_BPNS_So_34-ro-crate/ro-crate-metadata.json'\n\ntry:\n    ttl_file = serialize_rocrate_to_ttl(single_repo, \"emobon_bpns_so_34.ttl\")\n    print(f\"Single RO-Crate saved to: {ttl_file}\")\nexcept Exception as e:\n    print(f\"Error serializing single RO-Crate: {e}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# Serialize multiple RO-Crates to a combined TTL file\nrepos = [\n    \"https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_BPNS_So_34-ro-crate/ro-crate-metadata.json\",\n    \"https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_NRMCB_So_1-ro-crate/ro-crate-metadata.json\",\n    # \"https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_NRMCB_So_11-ro-crate/ro-crate-metadata.json\",\n    # 'https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_OOB_So_25-ro-crate/ro-crate-metadata.json',\n    # \"https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_RFormosa_So_11-ro-crate/ro-crate-metadata.json\"\n]\n\ntry:\n    combined_ttl = serialize_multiple_rocrates_to_ttl(repos, \"combined_emobon_rocrates.ttl\")\n    print(f\"Combined RO-Crates saved to: {combined_ttl}\")\nexcept Exception as e:\n    print(f\"Error serializing multiple RO-Crates: {e}\")\n\nError serializing single RO-Crate: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_BPNS_So_34-ro-crate/ro-crate-metadata.json\n\n==================================================\n\nProcessing 1/2: https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_BPNS_So_34-ro-crate/ro-crate-metadata.json\n  FAILED to process https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_BPNS_So_34-ro-crate/ro-crate-metadata.json: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_BPNS_So_34-ro-crate/ro-crate-metadata.json\nProcessing 2/2: https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_NRMCB_So_1-ro-crate/ro-crate-metadata.json\n  FAILED to process https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_NRMCB_So_1-ro-crate/ro-crate-metadata.json: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_NRMCB_So_1-ro-crate/ro-crate-metadata.json\n\nCombined RO-Crates serialized to TTL file: combined_emobon_rocrates.ttl\nCombined graph contains 0 triples\nCombined RO-Crates saved to: combined_emobon_rocrates.ttl\n\n\n\n\nUpload of the combined graph\n\nwith open(combined_ttl, 'r', encoding='utf-8') as f:\n    ttl_content = f.read()\n\nuri = \"http://example.org/graphs/emobon_combined\"\n# Use the Graph Store Protocol endpoint for Fuseki\ngsp_url = \"http://localhost:3030/rocrate/data?graph=\" + uri\n\nheaders = {\"Content-Type\": \"text/turtle\"}\n\nresp = requests.put(gsp_url, data=ttl_content.encode(\"utf-8\"), headers=headers, timeout=60)\n\n# raise for HTTP error\ntry:\n    resp.raise_for_status()\nexcept requests.HTTPError as e:\n    raise RuntimeError(f\"Upload failed: {resp.status_code} {resp.text}\") from e\n\n\nuri\n\n'http://example.org/graphs/emobon_combined'\n\n\n\n\nOriginal single graph upload\n\nrepo = 'https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_BPNS_So_34-ro-crate/ro-crate-metadata.json'\nfuseki_base = \"http://localhost:3030/rocrate\"\ntry:\n    r = process_github_rocrate(\n        repo,\n        fuseki_base,\n        graph_uri=\"http://example.org/rocrate/EMOBON_BPNS_So_34\",\n        fmt=\"turtle\")\n    print(\"Upload successful:\", r.status_code)\nexcept Exception as e:\n    print(\"Error:\", e)\n\nUpload successful: 200\n\n\n\nq = \"SELECT (COUNT(*) AS ?c) WHERE { ?s ?p ?o }\"\nr = requests.get(\"http://localhost:3030/rocrate/query\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\nprint(r.json())\n\n{'head': {'vars': ['c']}, 'results': {'bindings': [{'c': {'type': 'literal', 'datatype': 'http://www.w3.org/2001/XMLSchema#integer', 'value': '481'}}]}}\n\n\n\ndf = sparql_json_to_df(r.json())\nprint(df)\n\n     c\n0  481\n\n\n\n\nAdd more than one repository\n\nie. several emo-bon ro-crates\n\n\nrepos = [\n    \"https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_BPNS_So_34-ro-crate/ro-crate-metadata.json\",\n    \"https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_NRMCB_So_1-ro-crate/ro-crate-metadata.json\",\n    \"https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_NRMCB_So_11-ro-crate/ro-crate-metadata.json\",\n    'https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_OOB_So_25-ro-crate/ro-crate-metadata.json',\n    \"https://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_RFormosa_So_11-ro-crate/ro-crate-metadata.json\"\n]\nfor r in repos:\n    try:\n        resp = process_github_rocrate(\n            r, \"http://localhost:3030/rocrate\",\n            graph_uri=f\"http://example.org/rocrate/{r.split('/')[-2]}\")\n        print(r, \"-&gt;\", resp.status_code)\n    except Exception as e:\n        print(\"FAILED\", r, e)\n\nhttps://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_BPNS_So_34-ro-crate/ro-crate-metadata.json -&gt; 201\nhttps://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_NRMCB_So_1-ro-crate/ro-crate-metadata.json -&gt; 201\nhttps://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_NRMCB_So_11-ro-crate/ro-crate-metadata.json -&gt; 201\nhttps://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_OOB_So_25-ro-crate/ro-crate-metadata.json -&gt; 201\nhttps://raw.githubusercontent.com/emo-bon/analysis-results-cluster-01-crate/refs/heads/main/EMOBON_RFormosa_So_11-ro-crate/ro-crate-metadata.json -&gt; 201\n\n\n\nq = \"SELECT (COUNT(*) AS ?c) WHERE { ?s ?p ?o }\"\nr = requests.get(\"http://localhost:3030/rocrate/query\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\ndf = sparql_json_to_df(r.json())\nprint(df)\n\n     c\n0  481"
  },
  {
    "objectID": "biodata_pt/training_2511.html",
    "href": "biodata_pt/training_2511.html",
    "title": "EMO-BON Metagenomics: From Backend Integration to Frontend Processing",
    "section": "",
    "text": "Last change\n\n\n\n\n\nNovember 26, 2025\nEMO-BON establishes a long-term omics observatory for marine biodiversity through bimonthly sampling of coastal waters and both soft and hard sediments across more than 20 stations in Europe. Standard operating procedures are applied for sample collection, sequencing, and workflow analysis to ensure consistent taxonomic and functional annotation. FAIR principles are implemented using appropriate ontologies, RO-Crates, and a Python-based data analysis toolkit prepared for deployment in Virtual Research Environments (VREs).",
    "crumbs": [
      "Contents",
      "EMO-BON Metagenomics: From Backend Integration to Frontend Processing"
    ]
  },
  {
    "objectID": "biodata_pt/training_2511.html#session-1",
    "href": "biodata_pt/training_2511.html#session-1",
    "title": "EMO-BON Metagenomics: From Backend Integration to Frontend Processing",
    "section": "Session 1",
    "text": "Session 1\nOnline session hosted online on 3rd November (slides)",
    "crumbs": [
      "Contents",
      "EMO-BON Metagenomics: From Backend Integration to Frontend Processing"
    ]
  },
  {
    "objectID": "biodata_pt/training_2511.html#session-2",
    "href": "biodata_pt/training_2511.html#session-2",
    "title": "EMO-BON Metagenomics: From Backend Integration to Frontend Processing",
    "section": "Session 2",
    "text": "Session 2\nFaculty of Pharmacy of the University of Porto, 17th November during the ELIXIR Portugal All Hands 2025\nThis tutorial provides a set of minimal examples on how to generate a knowledge graph from set of RO-Crates, and use it as a sparQL endpoint either directly or using python rdflib. How to organize the data and build the RO-Crates is beyond scope, but galaxy tutorial is a great starting point.\nSecond part focused on a specific use case of EMO-BON data, the pilot implementation of the Virtual Research Environment is introduced, basic visualization and analysis demonstrated, however, more extensive resources will be provided when the VRE is fully deployed and operational.",
    "crumbs": [
      "Contents",
      "EMO-BON Metagenomics: From Backend Integration to Frontend Processing"
    ]
  },
  {
    "objectID": "biodata_pt/training_2511.html#environmental-setup",
    "href": "biodata_pt/training_2511.html#environmental-setup",
    "title": "EMO-BON Metagenomics: From Backend Integration to Frontend Processing",
    "section": "Environmental setup",
    "text": "Environmental setup\nThis setup serves is ubiquitus for both parts of the tutorial. We will clone two repositories and install one of them. To keep everything exactly the same, we create a designated folder\nmkdir emobon_demo\ncd emobon_demo\nCreate a dedicated conda/python environment\n# if you are using conda\nconda create -n \"emobon\" python=3.10   # or higher\nconda activate emobon\n\nPython resources\nJupyter notebooks are included in the tutorials repository, which we clone locally\n# create a folder\nmkdir biohap\ncd biohap\n\n# clone the repository into newly created folder\ngit clone https://github.com/Py-ualg/biohap.git\n\n# step into the repository\ncd biohap\n\n# install dependencies using pip\npip install -r requirements-biodata.txt\n\n# setup jupyter kernel\nipython kernel install --user --name \"biohap\"\nSeparate setup is provided for the Data Analysis Toolkit section.\n\n\nBackend setup\nAs we are going to work with EMO-BON metagenomics data, one way is to download some of the RO-Crates GitHub repository manually.\nEasier, however. is to clone the whole repository. Navigate back to the ..../emobon_demo/ and do:\nmkdir ro-crates\ncd ro-crates\n\ngit clone https://github.com/emo-bon/analysis-results-cluster-01-crate.git\nAs you see in the GH as well, you have now the RO-Crates per sample and corresponding .ttl files to simplify your life.\nWe will use fuseki server for a SPARQL endpoint. It is a java ndpoint, therefore, you might need to install java first if java -version command does not return anything or your version is &lt;17.0.\n\nLinuxWindows\n\n\nsudo apt update\nsudo apt install -y openjdk-17-jre-headless\njava -version\nHere comes the fuseki download itself. Please chose appropriate folder for this. For direct download visit this page.\nwget https://dlcdn.apache.org/jena/binaries/apache-jena-fuseki-5.6.0.tar.gz\n\n# open the archive\ntar -xvf apache-jena-fuseki-5.6.0.tar.gz\n\n\nFor java, if you have winget, you can follow these steps (not tested by the authors). Otherwise, download OpenJDK .exe file from microsoft and install it. You might need to close and reopen the command line window to see the updated version with java --version command in your PowerShell.\nDownload directly the fuseki 5.6.0 zip file from apache and extract the archive.",
    "crumbs": [
      "Contents",
      "EMO-BON Metagenomics: From Backend Integration to Frontend Processing"
    ]
  },
  {
    "objectID": "biodata_pt/training_2511.html#hands-on-tutorial",
    "href": "biodata_pt/training_2511.html#hands-on-tutorial",
    "title": "EMO-BON Metagenomics: From Backend Integration to Frontend Processing",
    "section": "Hands-on tutorial",
    "text": "Hands-on tutorial\n\nBackend data integrationData Analysis Toolkit\n\n\nThere are many parallel technologies to employ in each step. The pipeline here relies on fuseki for exposing the SPARQL endpoint and uses python to query the graph.\n\nRO-CratesFuseki ServerSPARQLPython SPARQLLocal + Public Endpoints\n\n\nA RO-Crate is an integrated view through which you can see an entire Research Object; the methods, the data, the output and the outcomes of a project or a piece of work. Linking all this together enables the sharing of research outputs with their context, as a coherent whole. https://www.researchobject.org\n\n\n\nImage credit: Goble, C. (2024, February 16). FAIR Digital Research Objects: Metadata Journeys. University of Auckland Seminar, Auckland. Zenodo. https://doi.org/10.5281/zenodo.10710142\n\n\nNote that we already have some of the EMO-BON RO-Crates locall in /emobon_demo/ro-crates/analysis-results-cluster-01-crate/.\nDescription of all the contents of a RO-Crate is contained in its root directory in the ro-crate-metadata.json, strictly with this name. We cannot upload directly the ro-crate-metadata.json files to the SPARQL endpoint, first they need to be serialized. We do that in the jupyter notebook.\nInitialize the jupyterlab server\n# ideally in the biohap folder\npython -m jupyterlab\nOpen biohap/biodata_pt/python_tools/01_fuseki_emobon.ipynb. Run Section 0, imports and function definitions. Section 1 serializes ro-crate0metadata.json files to turtle (.ttl) compatible with graph ingestion. Do note forget to change the relative path from your home to the analysis-results-cluster-01-crate folder.\n\n\nExpose your triples as a SPARQL end-point accessible over HTTP. Fuseki provides REST-style interaction with your RDF data, here running locally on localhost. Navigate to your downloaded fuseki files, open the archive if you have not done it yet and start the server\ncd apache-jena-fuseki-5.6.0/\n\n# start the server\n./fuseki-server\nThis should show you similar to\n15:46:47 INFO  Config          :: Fuseki Base = /home/david-palecek/coding/apache-jena-fuseki-5.6.0/run\n15:46:47 INFO  Config          :: No databases: dir=/home/david-palecek/coding/apache-jena-fuseki-5.6.0/run/configuration\n15:46:48 INFO  Config          :: UI Base = fuseki-server.jar\n15:46:48 INFO  Shiro           :: Shiro configuration: file:/home/david-palecek/coding/apache-jena-fuseki-5.6.0/run/shiro.ini\nNow opening a default fuseki port 3030 at http://localhost:3030/, you should see something like\n\n\n\nfuseki server\n\n\n\nUpload Dataset / Graph\nIn fuseki, go new dataset -&gt; give it a name emobon -&gt; add data -&gt; select the .ttl files we serialized in section RO-Crates and upload all or one by one.\nHow to create new dataset and upload data to it from python is shown in Section 3 and 4. of the biohap/biodata_pt/python_tools/01_fuseki_emobon.ipynb notebook.\nPseudo code for serialization of ro-crate-metadata.json and data upload (no new dataset creation) would look like\n# read the json file and convert it to a graph\nwith open(\".../ro-crate-metadata.json\", \"r\", encoding=\"utf-8\") as f:\n    jsonld_text = f.read()\n\ng = Graph()\n# rdflib accepts a JSON-LD string as input; base is optional\ng.parse(data=jsonld_text, format=\"json-ld\", publicID=base)\n\n# upload data to the endpoint\nresp = requests.put(\n    FUSEKI_URL,\n    data=g.serialize(format=\"turtle\").encode(\"utf-8\"),\n    headers={\"Content-Type\": \"text/turtle\"},\n    timeout=60,\n)\nThe example which integrates getting rocrates from GH directly is in biohap/biodata_pt/python_tools/02_fuseki_emobon_GH.ipynb or online.\n\n\n\nThe direct way from fuseki is to edit the query in actions. See more detailed but accesible introduction with examples. When you click query, the default query is shown\nPREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\nPREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\nSELECT * WHERE {\n  ?sub ?pred ?obj .\n} LIMIT 10\n, which queries all the triples in the graph.\n\n\n\n\n\n\nHow many triples do we have?\n\n\n\n\n\nSELECT (COUNT(*) as ?c)\nWHERE {\n  ?subject ?predicate ?object .\n}\nLIMIT 10\n\n\n\n\n\n\n\n\n\nFilter out all the text/html files.\n\n\n\n\n\nPREFIX sdo: &lt;http://schema.org/&gt;\n\nSELECT ?x ?dtype\nWHERE {\n  ?x sdo:encodingFormat ?dtype .\n  FILTER regex(str(?dtype), \"^text/html\", \"i\")\n}\n\n\n\n\n\n\n\n\n\nReturn also the sdo:downloadUrl of those files.\n\n\n\n\n\nPREFIX sdo: &lt;http://schema.org/&gt;\n\nSELECT ?x ?dtype ?durl\nWHERE {\n  ?x sdo:encodingFormat ?dtype ;\n    sdo:downloadUrl ?durl .\n  FILTER regex(str(?dtype), \"^text/html\", \"i\")\n}\n\n\n\nNow you can click the link of one of the Krona files, open them in the browser and with no surprise, it is a Krona plot.\nNow letâ€™s get the real metaGOflow outputs, specifically SSU taxonomy tables. There are several ways how to do it.\n1. RO-Crate browser EMBRC hosts the RO-Crate viewer for the EMO-BON data\n2. Local SPARQL Write a query to get the sdo:downloadUrl links, put them into your browser, which automatically triggers the download. Hint for the exercise below, match regex of the object on â€œSSU-taxonomy-summaryâ€.\n\n\n\n\n\n\nReturn SSU taxonomy download links.\n\n\n\n\n\nPREFIX sdo: &lt;http://schema.org/&gt;\n\nSELECT ?subject ?predicate ?object ?durl\nWHERE {\n  ?subject ?predicate ?object .\n  FILTER regex(str(?object), \"SSU-taxonomy-summary\", \"i\")\n  OPTIONAL { ?object sdo:downloadUrl ?durl }\n}\nLIMIT 50\n\n\n\n3. Use data version control (DVC) tool Shown in the python implementation of the above, which follows in the next section. For more on dvc, check its documentation.\n\n\nIt is possible to export the tables form the fuseki for subsequent work, but letâ€™s do everything seamlessly from the jupyter notebook.\nFirst we reproduce the queries in Section 2 of biohap/biodata_pt/python_tools/01_fuseki_emobon.ipynb notebook (or online)\nThe jupyterlab server should be still running, if not start it again in the .../biohap folder.\npython -m jupyterlab\nSince we have already ingested the triples from the RO-Crates, we just need to query the existing endpoint\nq = \"\"\"\nSELECT (COUNT(*) AS ?c) \nWHERE { \n  ?s ?p ?o\n}\n\"\"\"\n\nr = requests.get(\"http://localhost:3030/emobon/query\", params={\"query\": q}, headers={\"Accept\": \"application/sparql-results+json\"})\nprint(r.json())\nIn the requests target, you see we query emobon dataset, which we created earlier. The returned json is relatively easy to convert to a dataframe (sparql_json_to_df function)\ndef sparql_json_to_df(sparql_json):\n    \"\"\"\n    Convert a SPARQL SELECT query JSON result to a pandas DataFrame.\n    \n    Parameters\n    ----------\n    sparql_json : dict\n        JSON returned by Fuseki / SPARQL endpoint with Accept: application/sparql-results+json\n    \n    Returns\n    -------\n    pd.DataFrame\n    \"\"\"\n    vars_ = sparql_json.get(\"head\", {}).get(\"vars\", [])\n    rows = []\n\n    for binding in sparql_json.get(\"results\", {}).get(\"bindings\", []):\n        row = {}\n        for var in vars_:\n            # Some results might not bind all variables\n            if var in binding:\n                row[var] = binding[var][\"value\"]\n            else:\n                row[var] = None\n        rows.append(row)\n\n    df = pd.DataFrame(rows, columns=vars_)\n    return df\n\n\nThe point behind setting up SPARQL graph database comes together when combining local EMO-BON queries with public SPARQL endpoints from wikidata and UniProt. Demonstration is performed in Section 5 of the biohap/biodata_pt/python_tools/01_fuseki_emobon.ipynb.\n\n\n\n\n\n\nTip\n\n\n\nThere is a python wrapper for SPARQL SPARQLWrapper, which is pip installable and can be used as a standard python module but also as a command line script.\n\n\nBeyond only getting the data, Graph based deep learning is a fast-growing field.\n\n\n\n\n\n\nBecause (a) public SPARQL endpoint with all the EMO-BON data, we completaly separate this second part from the first part, and data starting point will be standard .csv tables, just compressed into .parquet files. Since Blue-Cloud 2026 virtual research environment does not exist, we will run all the analysis locally.\n\nSetupBasic Panel DashboardDeeper Interactive ModeHackathon\n\n\n# create a folder\nmkdir momics-demos\ncd momics-demos\n\n# clone the repository into newly created folder\ngit clone https://github.com/emo-bon/momics-demos.git\n\n# step into the repository\ncd momics-demos\n\n# install dependencies using pip\npip install -e .\n\n# setup jupyter kernel\nipython kernel install --user --name \"emobon\"\n\n\nAll dependencies were installed in the setup. Initialize the jupyter server with\ncd momics-demos\npython -m jupyterlab\nOpen wf2_diversity/diversities_panel.ipynb. It looks and it is a native python notebook code. However clicking the panel icon  initiates the dashboard.\nAfter getting familiar with the functionality, pick your favourite combination of taxon level + categoricall variable showing certain pattern on the first two PCA components.\n\n\nEvery dashboard is also available for interactive mode ..._interactive.ipynb. After discovering one of the main drivers, we would like to see what drives this difference.\nSelect one sample from each category and try to identify the taxa responsible from the variance.\nPossible options\n\nOne approach could be the permonova test removing the taxa one by one. Permonova is implemented in marine-omics-methods (marine-omics on PyPI).\nAlternatively compute correlation of each taxon with the PC1 and PC2, rank the features\nFit features as vectors onto PCoA (envfit). This is the most widely used method, especially in ecology (vegan package in R). In Python (via scikit-bio):\n\n    from skbio.stats.ordination import cca_scores\n\n    # envfit equivalent not built-in, but you can manually regress:\n    import scipy.stats as st\n\n    results = {}\n    for feature in abund.columns:\n        slope_x, _, r_x, _, _ = st.linregress(coords[\"PC1\"], abund[feature])\n        slope_y, _, r_y, _, _ = st.linregress(coords[\"PC2\"], abund[feature])\n        results[feature] = (r_x, r_y)\n\n    vectors = pd.DataFrame(results, index=[\"r_PC1\", \"r_PC2\"]).T\n\n\nThis is a free time to try your own ideas with the data building upon the existing functionality of the momics-demos. Do not hesitate to raise issues, and reach out.",
    "crumbs": [
      "Contents",
      "EMO-BON Metagenomics: From Backend Integration to Frontend Processing"
    ]
  }
]