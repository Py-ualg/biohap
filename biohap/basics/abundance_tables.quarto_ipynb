{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Abundance table preprocessing\n"
      ],
      "id": "e4f61555"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "date: 05/05/2025\n",
        "\n",
        "author: David Paleček [dpalecek@ualg.pt](mailto:dpalecek@ualg.pt)\n",
        "\n",
        "jupyter: python3\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "---\n",
        "\n",
        "\n",
        "**Work in progress**\n",
        "\n",
        "This is a personal commitment to understand the effect (variance) of abundance table normalization and scaling methods on downstream tasks, which may be differential analysis etc.\n",
        "\n",
        "::: {.callout-note collapse=\"true\" title=\"TODO\"}\n",
        "Compare R based methods to the python ones.\n",
        ":::\n",
        "\n",
        "Most well-known packages have the normalization methods implemented so raw data tables can be supplied to them, such as QIIME2 or refseq. For EMO-BON analysis, I do not use those (might be a mistake, because of bug risks), so I need to understand them properly.\n",
        "\n",
        "Load SSU combined taxonomy from 181 EMO-BON samplings.\n"
      ],
      "id": "a2886a6e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skbio.diversity import beta_diversity\n",
        "\n",
        "#| code-fold: false\n",
        "# read the data from github\n",
        "ssu_url = \"https://github.com/emo-bon/momics-demos/raw/refs/heads/main/data/parquet_files/metagoflow_analyses.SSU.parquet\"\n",
        "\n",
        "ssu = pd.read_parquet(ssu_url)\n",
        "\n",
        "# change abundance to int\n",
        "ssu['abundance'] = ssu['abundance'].astype(int)\n",
        "ssu.head()"
      ],
      "id": "4d2412c7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's order them by abundance\n"
      ],
      "id": "4eb86b16"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ssu.sort_values(by='abundance', inplace=True, ascending=False)\n",
        "\n",
        "ssu"
      ],
      "id": "aa0ec90f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Total Sum Scaling (TSS) followed by Square Root Transformation\n",
        "\n",
        "### TSS\n",
        "\n",
        "- converts raw counts into relative abundances, alternative name Relative Abundance Normalization. Simple division by sum of abundances in each sample separately.\n",
        "- Purpose: Adjusts for varying sequencing depths between samples.\n",
        "- [reference](https://doi.org/10.1371/journal.pcbi.1003531), McMurdie, P. J., & Holmes, S. (2014). Waste not, want not: why rarefying microbiome data is inadmissible. PLoS computational biology, 10(4), e1003531.\n",
        "\n",
        "### Square root transformation to relative abundances\n",
        "\n",
        "- This is a variance-stabilizing transformation — it reduces the effect of highly abundant taxa and improves comparability across samples.\n",
        "- It’s commonly used before distance-based analyses like Bray–Curtis dissimilarity or ordination (e.g., NMDS, PCoA).\n",
        "- [reference](https://doi.org/10.1007/s004420100716), Legendre, P., & Gallagher, E. D. (2001). Ecologically meaningful transformations for ordination of species data. Oecologia, 129(2), 271–280.\n",
        "\n",
        "Here is a function to pivot the taxonomy:\n"
      ],
      "id": "d9cef533"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def pivot_taxonomic_data(df: pd.DataFrame, values_col='abundance') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Prepares the taxonomic data (LSU and SSU tables) for analysis.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame containing taxonomic information.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A pivot table with taxonomic data.\n",
        "    \"\"\"\n",
        "    # Select relevant columns\n",
        "    df['taxonomic_concat'] = (\n",
        "        df['ncbi_tax_id'].astype(str) + \n",
        "        ';sk_' + df['superkingdom'].fillna('') + \n",
        "        ';k_' + df['kingdom'].fillna('') + \n",
        "        ';p_' + df['phylum'].fillna('') + \n",
        "        ';c_' + df['class'].fillna('') + \n",
        "        ';o_' + df['order'].fillna('') + \n",
        "        ';f_' + df['family'].fillna('') + \n",
        "        ';g_' + df['genus'].fillna('') + \n",
        "        ';s_' + df['species'].fillna('')\n",
        "    )\n",
        "    pivot_table = df.pivot_table(\n",
        "        index=['ncbi_tax_id','taxonomic_concat'], \n",
        "        columns='ref_code', \n",
        "        values=values_col,\n",
        "    ).fillna(0)\n",
        "    pivot_table = pivot_table.reset_index()\n",
        "    # change inex name\n",
        "    pivot_table.columns.name = None\n",
        "\n",
        "    return pivot_table"
      ],
      "id": "f0e88ba6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ", and methods to calculate to apply various scaling and normalization methods:\n"
      ],
      "id": "95f115ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: false\n",
        "def TSS(df, sampleIds='ref_code'):\n",
        "    \"\"\" Calculate TSS\"\"\"\n",
        "    df['abundance_TSS'] = df.groupby(sampleIds)['abundance'].transform(lambda x: x / x.sum())\n",
        "    return df"
      ],
      "id": "3ccef4ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Now I want to systematically transform and send downstream\n",
        "\n",
        "Downstream tasks are\n",
        "\n",
        "- Beta diversity\n",
        "- PCoA\n",
        "- ???\n"
      ],
      "id": "607fb226"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: false\n",
        "\n",
        "ssu = TSS(ssu)\n",
        "\n",
        "assert ssu[ssu['ref_code'] == 'EMOBON00009']['abundance_TSS'].sum() == 1.0\n",
        "ssu.head()"
      ],
      "id": "0d90274c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate and plot Beta diversity\n"
      ],
      "id": "2fc4b988"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import seaborn as sns\n",
        "\n",
        "pivot = pivot_taxonomic_data(ssu, values_col='abundance_TSS')\n",
        "metric = 'braycurtis'\n",
        "pivot.head()\n"
      ],
      "id": "4fa6200f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "beta = beta_diversity(metric, pivot.iloc[:, 2:].T)\n",
        "sns.heatmap(beta.to_data_frame(), vmin=0, vmax=1.0, cmap=\"viridis\")"
      ],
      "id": "6b0dbee4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How do I evaluate difference between methods?"
      ],
      "id": "1d13bb72"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}